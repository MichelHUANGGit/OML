{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary Classification on real-world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import norm\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation 3.1\n",
    "\n",
    "Select a dataset from the libsvm repository. The dataset should have at least 20 features\n",
    "and 1,000 training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mushrooms', <http.client.HTTPMessage at 0x16da29955b0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/mushrooms\", \"mushrooms\")\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a\", \"a9a\")\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a.t\",\"a9a.t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the a9a dataset**\n",
    "\n",
    "It has :\n",
    "- 32 561 samples (train) / 16 281 samples (test)\n",
    "- 123 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"mushrooms\"\n",
    "X, y = load_svmlight_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 112)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.toarray(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of the first 10 features : [0.00049237 0.05563762 0.38798621 0.10192024 0.00393895 0.45002462\n",
      " 0.39931068 0.31462334 0.00049237 0.28557361]\n"
     ]
    }
   ],
   "source": [
    "print(\"The frequency of the first 10 features :\", X_train.mean(axis=0)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The features seem very sparse, a lot are often empty**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting label 2 to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train == 2, -1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if X's feature are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1875, 0.3903123748998999)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X train has a constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train[:,77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, 77, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train[:,77])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a scaler class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Computing the mean and std along the features\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X-self.mean)/self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.727685308529284e-19, 1.000000000000008)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.mean(), scaled_X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8124 111\n"
     ]
    }
   ],
   "source": [
    "N, d = X_train.shape\n",
    "print(N, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation 3.2\n",
    "\n",
    "Given your dataset, implement the associated codes for $g_S$ , $\\nabla g_S$ and $\\nabla^2 g_S$ , where S\n",
    "is a set of random indices in {1, . . . , n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        y, \n",
    "        lbda=None,\n",
    "        regul=None,\n",
    "        batch_size=None,\n",
    "        grad_batch_size=None, \n",
    "        grad2_batch_size=None\n",
    "    ) -> None:\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.d = self.X.shape\n",
    "        # we add a regularization term if needed\n",
    "        self.lbda = lbda\n",
    "        self.regul = regul\n",
    "        # Initialize a default batch size\n",
    "        self.batch_size = batch_size\n",
    "        self.grad_batch_size = grad_batch_size\n",
    "        self.grad2_batch_size = grad2_batch_size\n",
    "        # tracking number of evaluations\n",
    "        self.func_evals = 0\n",
    "        self.grad_evals = 0\n",
    "    \n",
    "    def g_i(self, w, i):\n",
    "        self.func_evals += 1\n",
    "        return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
    "    \n",
    "    def __call__(self, w, indexes=None):\n",
    "        # Default batch size if indexes isn't given\n",
    "        indexes = self.batch_size if indexes is None else indexes\n",
    "        # We add the regularization term directly here and not in g_i\n",
    "        # (because it would be a redundant calculation to compute the mean of a term that doesn't depend on the batch chosen)\n",
    "        # This is ok bc we never actually call g_i directly outside of the class\n",
    "        if self.regul == 'l1':\n",
    "            regul = (self.lbda/2) * norm(w,1)\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = (self.lbda/2) * (norm(w,2)**2)\n",
    "        else :\n",
    "            regul = 0\n",
    "        return np.mean(self.g_i(w, indexes)) + regul\n",
    "    \n",
    "    def grad_i(self, w, i):\n",
    "        self.grad_evals += 1\n",
    "        exp_xiw = np.exp(self.X[i].dot(w))\n",
    "        return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
    "    \n",
    "    def grad(self, w, indexes=None):\n",
    "        indexes = self.grad_batch_size if indexes is None else indexes\n",
    "        grad = np.zeros(self.d)\n",
    "        for idx in indexes:\n",
    "            grad += self.grad_i(w, idx)\n",
    "        # regularization term\n",
    "        if self.regul == 'l1':\n",
    "            regul = (self.lbda/2) * np.sign(w)\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = self.lbda*w\n",
    "        else :\n",
    "            regul = 0\n",
    "        return grad/len(indexes) + regul\n",
    "    \n",
    "    def grad2_i(self, w, i):\n",
    "        # Returns a (d,d) shape array\n",
    "        self.grad_evals += self.d\n",
    "        exp_xiw = np.exp(self.X[i].dot(w))\n",
    "        scalar = 2 * exp_xiw * ( (exp_xiw**2 * (self.y[i]-1)) + (2 * exp_xiw - self.y[i]) ) / (1 + exp_xiw)**4\n",
    "        return scalar * self.X[i].reshape(self.d, 1) @ self.X[i].reshape(1, self.d)\n",
    "    \n",
    "    def grad2(self, w, indexes=None):\n",
    "        indexes = self.grad2_batch_size if indexes is None else indexes\n",
    "        grad2 = np.zeros(shape=(self.d, self.d))\n",
    "        for idx in indexes:\n",
    "            grad2 += self.grad2_i(w, idx)\n",
    "        # regularization term\n",
    "        if self.regul == 'l1':\n",
    "            regul = 0\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = self.lbda*np.identity(self.d)\n",
    "        else :\n",
    "            regul = 0\n",
    "        return grad2/len(indexes) + regul\n",
    "    \n",
    "    def get_L():\n",
    "        pass\n",
    "\n",
    "    def get_batch_L():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    regul=\"l1\",\n",
    "    lbda=1./np.sqrt(N)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it makes sense to use l1 regularization here because the features are very sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if my gradients implementation are correct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient error : 1.2588132595400352e-07\n",
      "Hessian error : 1.873825697209649e-09\n"
     ]
    }
   ],
   "source": [
    "# <30 seconds\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "# computing func/grad on a random point\n",
    "some_w = np.random.rand(d)\n",
    "\n",
    "print(\"gradient error :\", check_grad(g.__call__, g.grad, some_w, np.arange(N)))\n",
    "\n",
    "print(\"Hessian error :\", check_grad(g.grad, g.grad2, some_w, np.arange(N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Comparison of the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "Compare the performance of the subsampling Newton method from Section 2.1 and that of the\n",
    "stochastic quasi-Newton method of Section 2.2 with a (batch) stochastic gradient approach. You may reuse\n",
    "the stochastic gradient implementation from the course notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms2 import SubNewton, BatchArmijoLineSearch, BatchBFGS, BatchLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 1.8903447298689455\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.89e+00 | 6.16e-01:   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\algorithms2.py:83\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m batch_grad2 \u001b[38;5;241m=\u001b[39m loss_class\u001b[38;5;241m.\u001b[39mgrad2(w, grad2_idx)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Direction\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_grad2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m batch_grad)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Computing the batch loss (used in line search to avoid redundant recomputation)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss_class(w, grad_idx)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    grad2_batch_size=N//10,\n",
    "    max_epochs=20,\n",
    "    use_line_search=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Subsampling Newton method has a singular Hessian matrix for small batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n"
     ]
    }
   ],
   "source": [
    "for batch_size in 2**np.arange(10):\n",
    "    batch_idx = np.random.choice(N, size=batch_size)\n",
    "    try :\n",
    "        np.linalg.inv(g.grad2(w0, batch_idx))\n",
    "    except:\n",
    "        print(\"Singular matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However for batch_size = N (normal Newton), it is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    np.linalg.inv(g.grad2(w0, np.arange(N)))\n",
    "except:\n",
    "    print(\"Singular matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with grad2_batch_size = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.89e+00 | 6.16e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       0 | 1.89e+00 | 6.16e-01: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:47: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=50,\n",
    "    verbose=True,\n",
    "    use_line_search=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a full Hessian, the algorithm is still very unstable (infs or NaNs), displaying the local property of this method on non-convex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try again with a normalized X train :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=1/np.sqrt(N),\n",
    "    regul=\"l1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 1.775617512538282\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 1/1 [00:03<00:00,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:47: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=50,\n",
    "    verbose=True,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.01,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could redefine the method with a safety layer when the hessian is not invertible, by replacing the hessian by the identity matrix. <br>\n",
    "But that wouldn't solve the issue of having inf and NaNs, and that would be equivalent to batch stochastic gradient descent anyway. <br>\n",
    "Let's try to use l2 regularization (it might help making the Hessian invertible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=2./np.sqrt(N),\n",
    "    regul='l2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 2.445538117384306\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the initial loss was 1.3 without the regularization, meaning with regularization half of the loss is due to the penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 2.45e+00 | 3.68e-01: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "       1 | 2.46e+00 | 3.58e-01: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2 | 6.40e+00 | 4.64e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       2 | 6.40e+00 | 4.64e-01: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "       3 | 6.37e+00 | 4.82e-01: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "       4 | 6.25e+00 | 4.74e-01: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "       5 | 2.91e+00 | 3.03e-01: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "       6 | 1.59e+00 | 1.83e-01: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "       7 | 1.59e+00 | 1.80e-01: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "       8 | 1.35e+00 | 1.63e-01: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "       9 | 1.13e+00 | 1.02e-01: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "      10 | 1.13e+00 | 1.35e-01: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "      11 | 1.02e+00 | 9.52e-02: 100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12 | 4.76e+00 | 4.74e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:68: RuntimeWarning: overflow encountered in scalar power\n",
      "  scalar = 2 * exp_xiw * ( (exp_xiw**2 * (self.y[i]-1)) + (2 * exp_xiw - self.y[i]) ) / (1 + exp_xiw)**4\n",
      "      12 | 4.76e+00 | 4.74e-01: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "      13 | 4.66e+00 | 5.70e-01: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "      14 | 3.86e+00 | 3.72e-01: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "      15 | 3.76e+00 | 3.61e-01: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "      16 | 3.75e+00 | 3.67e-01: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "      17 | 3.54e+00 | 3.86e-01: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "      18 | 2.43e+00 | 3.34e-01: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "      19 | 2.43e+00 | 3.21e-01: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "      20 | 2.42e+00 | 3.30e-01: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "      21 | 2.41e+00 | 3.29e-01: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "      22 | 2.40e+00 | 2.67e-01: 100%|██████████| 1/1 [00:03<00:00,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: overflow encountered in scalar power\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:47: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_90488\\3396397676.py:48: RuntimeWarning: overflow encountered in multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=100,\n",
    "    use_line_search=True,\n",
    "    seed=1,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm giving up on the Newton method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=1/np.sqrt(N),\n",
    "    regul=\"l1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try Quasi-Newton BFGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 10/10 [00:00<00:00, 67.28it/s]\n",
      "       1 | 9.94e-01 | 6.37e-02: 100%|██████████| 10/10 [00:00<00:00, 58.71it/s]\n",
      "       2 | 8.23e-01 | 1.60e-01: 100%|██████████| 10/10 [00:00<00:00, 38.75it/s]\n",
      "       3 | 6.96e-01 | 6.63e-02: 100%|██████████| 10/10 [00:00<00:00, 71.50it/s]\n",
      "       4 | 6.36e-01 | 5.46e-02: 100%|██████████| 10/10 [00:00<00:00, 33.90it/s]\n",
      "       5 | 6.14e-01 | 4.71e-02: 100%|██████████| 10/10 [00:00<00:00, 70.64it/s]\n",
      "       6 | 6.05e-01 | 4.36e-02: 100%|██████████| 10/10 [00:00<00:00, 72.01it/s]\n",
      "       7 | 6.00e-01 | 5.07e-02: 100%|██████████| 10/10 [00:00<00:00, 74.11it/s]\n",
      "       8 | 5.98e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 68.61it/s]\n",
      "       9 | 5.97e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 70.07it/s]\n",
      "      10 | 5.96e-01 | 4.72e-02: 100%|██████████| 10/10 [00:00<00:00, 69.60it/s]\n",
      "      11 | 5.96e-01 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 69.39it/s]\n",
      "      12 | 5.95e-01 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 65.34it/s]\n",
      "      13 | 5.95e-01 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 72.27it/s]\n",
      "      14 | 5.94e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 71.46it/s]\n",
      "      15 | 5.94e-01 | 4.67e-02: 100%|██████████| 10/10 [00:00<00:00, 72.79it/s]\n",
      "      16 | 5.92e-01 | 5.13e-02: 100%|██████████| 10/10 [00:00<00:00, 72.26it/s]\n",
      "      17 | 5.92e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 67.42it/s]\n",
      "      18 | 5.91e-01 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 72.05it/s]\n",
      "      19 | 5.91e-01 | 4.41e-02: 100%|██████████| 10/10 [00:00<00:00, 73.50it/s]\n",
      "      20 | 5.91e-01 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 70.69it/s]\n",
      "      21 | 5.91e-01 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 71.21it/s]\n",
      "      22 | 5.91e-01 | 4.52e-02: 100%|██████████| 10/10 [00:00<00:00, 69.33it/s]\n",
      "      23 | 5.91e-01 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 62.26it/s]\n",
      "      24 | 5.90e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 61.08it/s]\n",
      "      25 | 5.90e-01 | 4.52e-02: 100%|██████████| 10/10 [00:00<00:00, 62.57it/s]\n",
      "      26 | 5.90e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 62.07it/s]\n",
      "      27 | 5.90e-01 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 62.24it/s]\n",
      "      28 | 5.90e-01 | 5.48e-02: 100%|██████████| 10/10 [00:00<00:00, 62.57it/s]\n",
      "      29 | 5.90e-01 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 66.84it/s]\n",
      "      30 | 5.90e-01 | 4.97e-02: 100%|██████████| 10/10 [00:00<00:00, 63.23it/s]\n",
      "      31 | 5.90e-01 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 63.68it/s]\n",
      "      32 | 5.89e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 64.12it/s]\n",
      "      33 | 5.89e-01 | 4.96e-02: 100%|██████████| 10/10 [00:00<00:00, 55.86it/s]\n",
      "      34 | 5.89e-01 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 58.55it/s]\n",
      "      35 | 5.89e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 58.67it/s]\n",
      "      36 | 5.89e-01 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 57.16it/s]\n",
      "      37 | 5.89e-01 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 57.80it/s]\n",
      "      38 | 5.89e-01 | 4.72e-02: 100%|██████████| 10/10 [00:00<00:00, 56.27it/s]\n",
      "      39 | 5.89e-01 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 59.25it/s]\n",
      "      40 | 5.89e-01 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 57.34it/s]\n",
      "      41 | 5.89e-01 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 63.98it/s]\n",
      "      42 | 5.89e-01 | 5.11e-02: 100%|██████████| 10/10 [00:00<00:00, 70.84it/s]\n",
      "      43 | 5.89e-01 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 56.59it/s]\n",
      "      44 | 5.89e-01 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 59.13it/s]\n",
      "      45 | 5.89e-01 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 69.28it/s]\n",
      "      46 | 5.89e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 63.02it/s]\n",
      "      47 | 5.89e-01 | 5.13e-02: 100%|██████████| 10/10 [00:00<00:00, 58.04it/s]\n",
      "      48 | 5.89e-01 | 5.00e-02: 100%|██████████| 10/10 [00:00<00:00, 62.14it/s]\n",
      "      49 | 5.89e-01 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 71.28it/s]\n",
      "      50 | 5.89e-01 | 4.67e-02: 100%|██████████| 10/10 [00:00<00:00, 73.95it/s]\n",
      "      51 | 5.89e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 73.70it/s]\n",
      "      52 | 5.89e-01 | 5.14e-02: 100%|██████████| 10/10 [00:00<00:00, 74.10it/s]\n",
      "      53 | 5.89e-01 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 77.10it/s]\n",
      "      54 | 5.89e-01 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 78.43it/s]\n",
      "      55 | 5.89e-01 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 76.05it/s]\n",
      "      56 | 5.89e-01 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 76.25it/s]\n",
      "      57 | 5.89e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 71.50it/s]\n",
      "      58 | 5.89e-01 | 5.36e-02: 100%|██████████| 10/10 [00:00<00:00, 72.11it/s]\n",
      "      59 | 5.89e-01 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 76.22it/s]\n",
      "      60 | 5.89e-01 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 70.70it/s]\n",
      "      61 | 5.89e-01 | 4.90e-02: 100%|██████████| 10/10 [00:00<00:00, 75.55it/s]\n",
      "      62 | 5.89e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 73.61it/s]\n",
      "      63 | 5.89e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 73.97it/s]\n",
      "      64 | 5.89e-01 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 72.65it/s]\n",
      "      65 | 5.89e-01 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 76.81it/s]\n",
      "      66 | 5.89e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 72.11it/s]\n",
      "      67 | 5.89e-01 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 66.87it/s]\n",
      "      68 | 5.89e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 72.55it/s]\n",
      "      69 | 5.89e-01 | 4.67e-02: 100%|██████████| 10/10 [00:00<00:00, 73.01it/s]\n",
      "      70 | 5.89e-01 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 68.88it/s]\n",
      "      71 | 5.89e-01 | 5.20e-02: 100%|██████████| 10/10 [00:00<00:00, 77.64it/s]\n",
      "      72 | 5.89e-01 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 37.88it/s]\n",
      "      73 | 5.89e-01 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 79.90it/s]\n",
      "      74 | 5.89e-01 | 4.95e-02: 100%|██████████| 10/10 [00:00<00:00, 76.64it/s]\n",
      "      75 | 5.89e-01 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 79.53it/s]\n",
      "      76 | 5.89e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 74.47it/s]\n",
      "      77 | 5.89e-01 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 66.83it/s]\n",
      "      78 | 5.89e-01 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 73.20it/s]\n",
      "      79 | 5.89e-01 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 63.79it/s]\n",
      "      80 | 5.89e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 77.46it/s]\n",
      "      81 | 5.89e-01 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 77.34it/s]\n",
      "      82 | 5.89e-01 | 5.11e-02: 100%|██████████| 10/10 [00:00<00:00, 73.98it/s]\n",
      "      83 | 5.89e-01 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 73.84it/s]\n",
      "      84 | 5.89e-01 | 5.18e-02: 100%|██████████| 10/10 [00:00<00:00, 74.11it/s]\n",
      "      85 | 5.89e-01 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 74.16it/s]\n",
      "      86 | 5.89e-01 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 77.25it/s]\n",
      "      87 | 5.89e-01 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 72.88it/s]\n",
      "      88 | 5.89e-01 | 5.16e-02: 100%|██████████| 10/10 [00:00<00:00, 76.62it/s]\n",
      "      89 | 5.89e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 68.16it/s]\n",
      "      90 | 5.89e-01 | 4.86e-02: 100%|██████████| 10/10 [00:00<00:00, 68.86it/s]\n",
      "      91 | 5.89e-01 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 72.16it/s]\n",
      "      92 | 5.89e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 71.72it/s]\n",
      "      93 | 5.89e-01 | 5.19e-02: 100%|██████████| 10/10 [00:00<00:00, 73.21it/s]\n",
      "      94 | 5.89e-01 | 5.26e-02: 100%|██████████| 10/10 [00:00<00:00, 69.12it/s]\n",
      "      95 | 5.89e-01 | 4.67e-02: 100%|██████████| 10/10 [00:00<00:00, 69.05it/s]\n",
      "      96 | 5.89e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 73.97it/s]\n",
      "      97 | 5.89e-01 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 73.21it/s]\n",
      "      98 | 5.89e-01 | 4.58e-02: 100%|██████████| 10/10 [00:00<00:00, 73.89it/s]\n",
      "      99 | 5.89e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 70.07it/s]\n"
     ]
    }
   ],
   "source": [
    "#<1 min\n",
    "w1, loss_logs1, norm_logs1 = BatchBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    ground_truth=None,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 20/20 [00:00<00:00, 282.34it/s]\n",
      "       1 | 8.94e-01 | 9.99e-02: 100%|██████████| 20/20 [00:00<00:00, 291.35it/s]\n",
      "       2 | 6.57e-01 | 5.82e-02: 100%|██████████| 20/20 [00:00<00:00, 291.92it/s]\n",
      "       3 | 6.03e-01 | 5.84e-02: 100%|██████████| 20/20 [00:00<00:00, 313.44it/s]\n",
      "       4 | 5.94e-01 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 322.34it/s]\n",
      "       5 | 5.92e-01 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 323.30it/s]\n",
      "       6 | 5.91e-01 | 4.62e-02: 100%|██████████| 20/20 [00:00<00:00, 313.17it/s]\n",
      "       7 | 5.90e-01 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 292.98it/s]\n",
      "       8 | 5.88e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 292.28it/s]\n",
      "       9 | 5.87e-01 | 4.92e-02: 100%|██████████| 20/20 [00:00<00:00, 311.43it/s]\n",
      "      10 | 5.87e-01 | 4.87e-02: 100%|██████████| 20/20 [00:00<00:00, 304.68it/s]\n",
      "      11 | 5.86e-01 | 5.31e-02: 100%|██████████| 20/20 [00:00<00:00, 312.37it/s]\n",
      "      12 | 5.86e-01 | 5.42e-02: 100%|██████████| 20/20 [00:00<00:00, 294.88it/s]\n",
      "      13 | 5.86e-01 | 4.69e-02: 100%|██████████| 20/20 [00:00<00:00, 285.56it/s]\n",
      "      14 | 5.86e-01 | 4.75e-02: 100%|██████████| 20/20 [00:00<00:00, 305.00it/s]\n",
      "      15 | 5.85e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 311.83it/s]\n",
      "      16 | 5.85e-01 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 303.28it/s]\n",
      "      17 | 5.85e-01 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 308.32it/s]\n",
      "      18 | 5.85e-01 | 5.21e-02: 100%|██████████| 20/20 [00:00<00:00, 313.94it/s]\n",
      "      19 | 5.85e-01 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 314.61it/s]\n",
      "      20 | 5.84e-01 | 5.53e-02: 100%|██████████| 20/20 [00:00<00:00, 295.06it/s]\n",
      "      21 | 5.84e-01 | 4.86e-02: 100%|██████████| 20/20 [00:00<00:00, 317.20it/s]\n",
      "      22 | 5.84e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 309.66it/s]\n",
      "      23 | 5.84e-01 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 311.07it/s]\n",
      "      24 | 5.84e-01 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 306.95it/s]\n",
      "      25 | 5.84e-01 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 308.76it/s]\n",
      "      26 | 5.84e-01 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 303.31it/s]\n",
      "      27 | 5.84e-01 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 310.22it/s]\n",
      "      28 | 5.84e-01 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 320.80it/s]\n",
      "      29 | 5.84e-01 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 309.97it/s]\n",
      "      30 | 5.84e-01 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 302.80it/s]\n",
      "      31 | 5.84e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 309.02it/s]\n",
      "      32 | 5.84e-01 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 308.97it/s]\n",
      "      33 | 5.84e-01 | 5.41e-02: 100%|██████████| 20/20 [00:00<00:00, 326.56it/s]\n",
      "      34 | 5.84e-01 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 309.31it/s]\n",
      "      35 | 5.84e-01 | 4.66e-02: 100%|██████████| 20/20 [00:00<00:00, 313.17it/s]\n",
      "      36 | 5.84e-01 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 312.22it/s]\n",
      "      37 | 5.84e-01 | 4.51e-02: 100%|██████████| 20/20 [00:00<00:00, 315.99it/s]\n",
      "      38 | 5.84e-01 | 5.45e-02: 100%|██████████| 20/20 [00:00<00:00, 181.60it/s]\n",
      "      39 | 5.84e-01 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 298.31it/s]\n",
      "      40 | 5.84e-01 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 319.79it/s]\n",
      "      41 | 5.84e-01 | 5.28e-02: 100%|██████████| 20/20 [00:00<00:00, 302.83it/s]\n",
      "      42 | 5.84e-01 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 309.29it/s]\n",
      "      43 | 5.84e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 317.98it/s]\n",
      "      44 | 5.84e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 314.39it/s]\n",
      "      45 | 5.84e-01 | 5.30e-02: 100%|██████████| 20/20 [00:00<00:00, 310.36it/s]\n",
      "      46 | 5.84e-01 | 5.39e-02: 100%|██████████| 20/20 [00:00<00:00, 310.12it/s]\n",
      "      47 | 5.84e-01 | 4.60e-02: 100%|██████████| 20/20 [00:00<00:00, 313.96it/s]\n",
      "      48 | 5.84e-01 | 4.87e-02: 100%|██████████| 20/20 [00:00<00:00, 313.56it/s]\n",
      "      49 | 5.84e-01 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 319.22it/s]\n",
      "      50 | 5.84e-01 | 4.92e-02: 100%|██████████| 20/20 [00:00<00:00, 291.04it/s]\n",
      "      51 | 5.84e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 297.97it/s]\n",
      "      52 | 5.84e-01 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 312.08it/s]\n",
      "      53 | 5.84e-01 | 5.02e-02: 100%|██████████| 20/20 [00:00<00:00, 303.52it/s]\n",
      "      54 | 5.84e-01 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 317.70it/s]\n",
      "      55 | 5.84e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 303.55it/s]\n",
      "      56 | 5.84e-01 | 5.52e-02: 100%|██████████| 20/20 [00:00<00:00, 304.87it/s]\n",
      "      57 | 5.84e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 313.52it/s]\n",
      "      58 | 5.84e-01 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 308.69it/s]\n",
      "      59 | 5.84e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 306.45it/s]\n",
      "      60 | 5.84e-01 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 308.76it/s]\n",
      "      61 | 5.84e-01 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 305.41it/s]\n",
      "      62 | 5.84e-01 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 316.38it/s]\n",
      "      63 | 5.84e-01 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 311.41it/s]\n",
      "      64 | 5.84e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 302.71it/s]\n",
      "      65 | 5.84e-01 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 306.11it/s]\n",
      "      66 | 5.84e-01 | 5.24e-02: 100%|██████████| 20/20 [00:00<00:00, 302.30it/s]\n",
      "      67 | 5.84e-01 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 303.90it/s]\n",
      "      68 | 5.84e-01 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 299.32it/s]\n",
      "      69 | 5.84e-01 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 307.53it/s]\n",
      "      70 | 5.84e-01 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 298.55it/s]\n",
      "      71 | 5.84e-01 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 313.52it/s]\n",
      "      72 | 5.84e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 316.94it/s]\n",
      "      73 | 5.84e-01 | 5.08e-02: 100%|██████████| 20/20 [00:00<00:00, 312.48it/s]\n",
      "      74 | 5.84e-01 | 5.10e-02: 100%|██████████| 20/20 [00:00<00:00, 312.59it/s]\n",
      "      75 | 5.84e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 317.55it/s]\n",
      "      76 | 5.84e-01 | 5.45e-02: 100%|██████████| 20/20 [00:00<00:00, 303.28it/s]\n",
      "      77 | 5.84e-01 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 303.64it/s]\n",
      "      78 | 5.84e-01 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 306.92it/s]\n",
      "      79 | 5.84e-01 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 313.05it/s]\n",
      "      80 | 5.84e-01 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 317.49it/s]\n",
      "      81 | 5.84e-01 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 298.24it/s]\n",
      "      82 | 5.84e-01 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 316.65it/s]\n",
      "      83 | 5.84e-01 | 4.65e-02: 100%|██████████| 20/20 [00:00<00:00, 315.42it/s]\n",
      "      84 | 5.84e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 325.74it/s]\n",
      "      85 | 5.84e-01 | 4.97e-02: 100%|██████████| 20/20 [00:00<00:00, 287.82it/s]\n",
      "      86 | 5.84e-01 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 321.30it/s]\n",
      "      87 | 5.84e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 308.42it/s]\n",
      "      88 | 5.84e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 317.13it/s]\n",
      "      89 | 5.84e-01 | 5.20e-02: 100%|██████████| 20/20 [00:00<00:00, 304.93it/s]\n",
      "      90 | 5.84e-01 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 313.45it/s]\n",
      "      91 | 5.84e-01 | 4.86e-02: 100%|██████████| 20/20 [00:00<00:00, 315.69it/s]\n",
      "      92 | 5.84e-01 | 5.09e-02: 100%|██████████| 20/20 [00:00<00:00, 310.67it/s]\n",
      "      93 | 5.84e-01 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 315.45it/s]\n",
      "      94 | 5.84e-01 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 305.44it/s]\n",
      "      95 | 5.84e-01 | 5.13e-02: 100%|██████████| 20/20 [00:00<00:00, 316.99it/s]\n",
      "      96 | 5.84e-01 | 5.09e-02: 100%|██████████| 20/20 [00:00<00:00, 323.06it/s]\n",
      "      97 | 5.84e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 269.25it/s]\n",
      "      98 | 5.84e-01 | 4.75e-02: 100%|██████████| 20/20 [00:00<00:00, 304.91it/s]\n",
      "      99 | 5.84e-01 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 325.34it/s]\n"
     ]
    }
   ],
   "source": [
    "#<1 min\n",
    "w1_, loss_logs1_, norm_logs1_ = BatchBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    ground_truth=None,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L-BFGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 10/10 [00:00<00:00, 142.71it/s]\n",
      "       1 | 1.05e+00 | 6.17e-02: 100%|██████████| 10/10 [00:00<00:00, 153.94it/s]\n",
      "       2 | 9.92e-01 | 6.43e-02: 100%|██████████| 10/10 [00:00<00:00, 168.38it/s]\n",
      "       3 | 9.49e-01 | 5.88e-02: 100%|██████████| 10/10 [00:00<00:00, 166.45it/s]\n",
      "       4 | 8.58e-01 | 1.16e-01: 100%|██████████| 10/10 [00:00<00:00, 178.06it/s]\n",
      "       5 | 6.81e-01 | 1.14e-01: 100%|██████████| 10/10 [00:00<00:00, 174.06it/s]\n",
      "       6 | 6.24e-01 | 5.20e-02: 100%|██████████| 10/10 [00:00<00:00, 167.49it/s]\n",
      "       7 | 6.03e-01 | 4.62e-02: 100%|██████████| 10/10 [00:00<00:00, 169.81it/s]\n",
      "       8 | 5.99e-01 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 163.21it/s]\n",
      "       9 | 5.97e-01 | 4.57e-02: 100%|██████████| 10/10 [00:00<00:00, 161.56it/s]\n",
      "      10 | 5.96e-01 | 4.78e-02: 100%|██████████| 10/10 [00:00<00:00, 179.61it/s]\n",
      "      11 | 5.95e-01 | 5.37e-02: 100%|██████████| 10/10 [00:00<00:00, 177.92it/s]\n",
      "      12 | 5.94e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 176.75it/s]\n",
      "      13 | 5.94e-01 | 4.44e-02: 100%|██████████| 10/10 [00:00<00:00, 139.87it/s]\n",
      "      14 | 5.93e-01 | 4.45e-02: 100%|██████████| 10/10 [00:00<00:00, 178.98it/s]\n",
      "      15 | 5.93e-01 | 4.57e-02: 100%|██████████| 10/10 [00:00<00:00, 176.87it/s]\n",
      "      16 | 5.93e-01 | 4.71e-02: 100%|██████████| 10/10 [00:00<00:00, 170.16it/s]\n",
      "      17 | 5.93e-01 | 5.16e-02: 100%|██████████| 10/10 [00:00<00:00, 171.20it/s]\n",
      "      18 | 5.93e-01 | 4.51e-02: 100%|██████████| 10/10 [00:00<00:00, 172.29it/s]\n",
      "      19 | 5.92e-01 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 131.84it/s]\n",
      "      20 | 5.92e-01 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 170.73it/s]\n",
      "      21 | 5.92e-01 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 175.02it/s]\n",
      "      22 | 5.92e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 180.15it/s]\n",
      "      23 | 5.92e-01 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 153.54it/s]\n",
      "      24 | 5.92e-01 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 165.51it/s]\n",
      "      25 | 5.92e-01 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 166.94it/s]\n",
      "      26 | 5.92e-01 | 4.77e-02: 100%|██████████| 10/10 [00:00<00:00, 170.00it/s]\n",
      "      27 | 5.92e-01 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 153.24it/s]\n",
      "      28 | 5.92e-01 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 169.88it/s]\n",
      "      29 | 5.92e-01 | 4.07e-02: 100%|██████████| 10/10 [00:00<00:00, 157.15it/s]\n",
      "      30 | 5.91e-01 | 5.35e-02: 100%|██████████| 10/10 [00:00<00:00, 160.94it/s]\n",
      "      31 | 5.91e-01 | 4.46e-02: 100%|██████████| 10/10 [00:00<00:00, 175.05it/s]\n",
      "      32 | 5.91e-01 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 161.30it/s]\n",
      "      33 | 5.91e-01 | 4.55e-02: 100%|██████████| 10/10 [00:00<00:00, 169.03it/s]\n",
      "      34 | 5.91e-01 | 4.68e-02: 100%|██████████| 10/10 [00:00<00:00, 166.32it/s]\n",
      "      35 | 5.91e-01 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 163.30it/s]\n",
      "      36 | 5.91e-01 | 4.95e-02: 100%|██████████| 10/10 [00:00<00:00, 160.17it/s]\n",
      "      37 | 5.91e-01 | 4.52e-02: 100%|██████████| 10/10 [00:00<00:00, 153.98it/s]\n",
      "      38 | 5.91e-01 | 4.51e-02: 100%|██████████| 10/10 [00:00<00:00, 167.04it/s]\n",
      "      39 | 5.91e-01 | 4.58e-02: 100%|██████████| 10/10 [00:00<00:00, 169.89it/s]\n",
      "      40 | 5.91e-01 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 175.06it/s]\n",
      "      41 | 5.91e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 172.59it/s]\n",
      "      42 | 5.91e-01 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 176.46it/s]\n",
      "      43 | 5.91e-01 | 4.28e-02: 100%|██████████| 10/10 [00:00<00:00, 173.59it/s]\n",
      "      44 | 5.91e-01 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 172.03it/s]\n",
      "      45 | 5.90e-01 | 4.25e-02: 100%|██████████| 10/10 [00:00<00:00, 158.89it/s]\n",
      "      46 | 5.90e-01 | 4.41e-02: 100%|██████████| 10/10 [00:00<00:00, 157.39it/s]\n",
      "      47 | 5.91e-01 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 176.08it/s]\n",
      "      48 | 5.90e-01 | 4.65e-02: 100%|██████████| 10/10 [00:00<00:00, 175.00it/s]\n",
      "      49 | 5.90e-01 | 4.55e-02: 100%|██████████| 10/10 [00:00<00:00, 179.56it/s]\n",
      "      50 | 5.90e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 161.73it/s]\n",
      "      51 | 5.90e-01 | 4.41e-02: 100%|██████████| 10/10 [00:00<00:00, 168.56it/s]\n",
      "      52 | 5.90e-01 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 173.99it/s]\n",
      "      53 | 5.90e-01 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 173.01it/s]\n",
      "      54 | 5.90e-01 | 5.31e-02: 100%|██████████| 10/10 [00:00<00:00, 168.02it/s]\n",
      "      55 | 5.90e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 154.48it/s]\n",
      "      56 | 5.90e-01 | 5.40e-02: 100%|██████████| 10/10 [00:00<00:00, 175.32it/s]\n",
      "      57 | 5.90e-01 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 170.09it/s]\n",
      "      58 | 5.90e-01 | 4.40e-02: 100%|██████████| 10/10 [00:00<00:00, 162.52it/s]\n",
      "      59 | 5.90e-01 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 156.09it/s]\n",
      "      60 | 5.90e-01 | 4.53e-02: 100%|██████████| 10/10 [00:00<00:00, 159.50it/s]\n",
      "      61 | 5.90e-01 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 159.62it/s]\n",
      "      62 | 5.90e-01 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 171.63it/s]\n",
      "      63 | 5.90e-01 | 5.47e-02: 100%|██████████| 10/10 [00:00<00:00, 167.85it/s]\n",
      "      64 | 5.90e-01 | 4.51e-02: 100%|██████████| 10/10 [00:00<00:00, 166.49it/s]\n",
      "      65 | 5.89e-01 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 158.92it/s]\n",
      "      66 | 5.89e-01 | 4.68e-02: 100%|██████████| 10/10 [00:00<00:00, 173.30it/s]\n",
      "      67 | 5.90e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 163.23it/s]\n",
      "      68 | 5.89e-01 | 5.11e-02: 100%|██████████| 10/10 [00:00<00:00, 148.74it/s]\n",
      "      69 | 5.89e-01 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 170.36it/s]\n",
      "      70 | 5.89e-01 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 159.97it/s]\n",
      "      71 | 5.89e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 168.34it/s]\n",
      "      72 | 5.89e-01 | 4.40e-02: 100%|██████████| 10/10 [00:00<00:00, 166.22it/s]\n",
      "      73 | 5.89e-01 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 154.11it/s]\n",
      "      74 | 5.89e-01 | 4.49e-02: 100%|██████████| 10/10 [00:00<00:00, 176.35it/s]\n",
      "      75 | 5.89e-01 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 144.88it/s]\n",
      "      76 | 5.89e-01 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 167.48it/s]\n",
      "      77 | 5.89e-01 | 4.35e-02: 100%|██████████| 10/10 [00:00<00:00, 156.30it/s]\n",
      "      78 | 5.89e-01 | 4.40e-02: 100%|██████████| 10/10 [00:00<00:00, 164.33it/s]\n",
      "      79 | 5.89e-01 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 162.07it/s]\n",
      "      80 | 5.89e-01 | 4.43e-02: 100%|██████████| 10/10 [00:00<00:00, 167.73it/s]\n",
      "      81 | 5.89e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 165.47it/s]\n",
      "      82 | 5.89e-01 | 4.78e-02: 100%|██████████| 10/10 [00:00<00:00, 165.83it/s]\n",
      "      83 | 5.89e-01 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 176.22it/s]\n",
      "      84 | 5.89e-01 | 5.37e-02: 100%|██████████| 10/10 [00:00<00:00, 171.30it/s]\n",
      "      85 | 5.89e-01 | 4.97e-02: 100%|██████████| 10/10 [00:00<00:00, 172.17it/s]\n",
      "      86 | 5.89e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 168.43it/s]\n",
      "      87 | 5.89e-01 | 4.57e-02: 100%|██████████| 10/10 [00:00<00:00, 177.87it/s]\n",
      "      88 | 5.89e-01 | 4.65e-02: 100%|██████████| 10/10 [00:00<00:00, 162.66it/s]\n",
      "      89 | 5.88e-01 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 174.17it/s]\n",
      "      90 | 5.88e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 160.50it/s]\n",
      "      91 | 5.88e-01 | 4.80e-02: 100%|██████████| 10/10 [00:00<00:00, 174.36it/s]\n",
      "      92 | 5.88e-01 | 4.56e-02: 100%|██████████| 10/10 [00:00<00:00, 164.61it/s]\n",
      "      93 | 5.88e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 168.14it/s]\n",
      "      94 | 5.88e-01 | 4.54e-02: 100%|██████████| 10/10 [00:00<00:00, 170.60it/s]\n",
      "      95 | 5.88e-01 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 163.74it/s]\n",
      "      96 | 5.88e-01 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 151.52it/s]\n",
      "      97 | 5.88e-01 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 172.77it/s]\n",
      "      98 | 5.88e-01 | 4.51e-02: 100%|██████████| 10/10 [00:00<00:00, 165.12it/s]\n",
      "      99 | 5.88e-01 | 4.39e-02: 100%|██████████| 10/10 [00:00<00:00, 160.25it/s]\n"
     ]
    }
   ],
   "source": [
    "#< 1 min\n",
    "w2, loss_logs2, norm_logs2 = BatchLBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    m=2,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 20/20 [00:00<00:00, 250.16it/s]\n",
      "       1 | 9.51e-01 | 5.86e-02: 100%|██████████| 20/20 [00:00<00:00, 274.19it/s]\n",
      "       2 | 7.94e-01 | 1.22e-01: 100%|██████████| 20/20 [00:00<00:00, 283.52it/s]\n",
      "       3 | 6.63e-01 | 7.22e-02: 100%|██████████| 20/20 [00:00<00:00, 292.80it/s]\n",
      "       4 | 6.22e-01 | 5.80e-02: 100%|██████████| 20/20 [00:00<00:00, 277.69it/s]\n",
      "       5 | 6.09e-01 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 288.70it/s]\n",
      "       6 | 6.06e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 280.14it/s]\n",
      "       7 | 6.04e-01 | 4.42e-02: 100%|██████████| 20/20 [00:00<00:00, 287.66it/s]\n",
      "       8 | 6.03e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 275.43it/s]\n",
      "       9 | 5.99e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 271.37it/s]\n",
      "      10 | 5.97e-01 | 4.33e-02: 100%|██████████| 20/20 [00:00<00:00, 289.52it/s]\n",
      "      11 | 5.97e-01 | 5.11e-02: 100%|██████████| 20/20 [00:00<00:00, 263.74it/s]\n",
      "      12 | 5.97e-01 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 284.42it/s]\n",
      "      13 | 5.97e-01 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 268.36it/s]\n",
      "      14 | 5.96e-01 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 280.50it/s]\n",
      "      15 | 5.96e-01 | 4.33e-02: 100%|██████████| 20/20 [00:00<00:00, 276.40it/s]\n",
      "      16 | 5.96e-01 | 4.42e-02: 100%|██████████| 20/20 [00:00<00:00, 282.84it/s]\n",
      "      17 | 5.96e-01 | 4.65e-02: 100%|██████████| 20/20 [00:00<00:00, 281.89it/s]\n",
      "      18 | 5.96e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 281.42it/s]\n",
      "      19 | 5.96e-01 | 4.71e-02: 100%|██████████| 20/20 [00:00<00:00, 286.14it/s]\n",
      "      20 | 5.96e-01 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 284.89it/s]\n",
      "      21 | 5.95e-01 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 295.19it/s]\n",
      "      22 | 5.95e-01 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 285.60it/s]\n",
      "      23 | 5.95e-01 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 283.46it/s]\n",
      "      24 | 5.95e-01 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 290.10it/s]\n",
      "      25 | 5.95e-01 | 5.25e-02: 100%|██████████| 20/20 [00:00<00:00, 278.86it/s]\n",
      "      26 | 5.95e-01 | 4.58e-02: 100%|██████████| 20/20 [00:00<00:00, 276.85it/s]\n",
      "      27 | 5.95e-01 | 4.24e-02: 100%|██████████| 20/20 [00:00<00:00, 276.66it/s]\n",
      "      28 | 5.95e-01 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 277.45it/s]\n",
      "      29 | 5.95e-01 | 5.33e-02: 100%|██████████| 20/20 [00:00<00:00, 282.24it/s]\n",
      "      30 | 5.94e-01 | 4.39e-02: 100%|██████████| 20/20 [00:00<00:00, 292.96it/s]\n",
      "      31 | 5.94e-01 | 5.24e-02: 100%|██████████| 20/20 [00:00<00:00, 286.23it/s]\n",
      "      32 | 5.94e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 282.35it/s]\n",
      "      33 | 5.94e-01 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 277.83it/s]\n",
      "      34 | 5.94e-01 | 5.14e-02: 100%|██████████| 20/20 [00:00<00:00, 277.46it/s]\n",
      "      35 | 5.94e-01 | 4.14e-02: 100%|██████████| 20/20 [00:00<00:00, 148.79it/s]\n",
      "      36 | 5.94e-01 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 291.65it/s]\n",
      "      37 | 5.93e-01 | 4.40e-02: 100%|██████████| 20/20 [00:00<00:00, 289.38it/s]\n",
      "      38 | 5.94e-01 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 285.26it/s]\n",
      "      39 | 5.94e-01 | 4.97e-02: 100%|██████████| 20/20 [00:00<00:00, 280.53it/s]\n",
      "      40 | 5.93e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 295.35it/s]\n",
      "      41 | 5.93e-01 | 4.43e-02: 100%|██████████| 20/20 [00:00<00:00, 281.03it/s]\n",
      "      42 | 5.93e-01 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 295.15it/s]\n",
      "      43 | 5.93e-01 | 4.19e-02: 100%|██████████| 20/20 [00:00<00:00, 277.45it/s]\n",
      "      44 | 5.93e-01 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 283.28it/s]\n",
      "      45 | 5.93e-01 | 4.92e-02: 100%|██████████| 20/20 [00:00<00:00, 290.88it/s]\n",
      "      46 | 5.93e-01 | 4.48e-02: 100%|██████████| 20/20 [00:00<00:00, 284.70it/s]\n",
      "      47 | 5.93e-01 | 4.66e-02: 100%|██████████| 20/20 [00:00<00:00, 289.02it/s]\n",
      "      48 | 5.93e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 287.63it/s]\n",
      "      49 | 5.92e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 281.00it/s]\n",
      "      50 | 5.92e-01 | 4.48e-02: 100%|██████████| 20/20 [00:00<00:00, 292.58it/s]\n",
      "      51 | 5.92e-01 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 282.94it/s]\n",
      "      52 | 5.92e-01 | 4.56e-02: 100%|██████████| 20/20 [00:00<00:00, 281.26it/s]\n",
      "      53 | 5.92e-01 | 4.49e-02: 100%|██████████| 20/20 [00:00<00:00, 301.69it/s]\n",
      "      54 | 5.92e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 283.87it/s]\n",
      "      55 | 5.92e-01 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 292.40it/s]\n",
      "      56 | 5.92e-01 | 5.55e-02: 100%|██████████| 20/20 [00:00<00:00, 284.43it/s]\n",
      "      57 | 5.92e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 274.09it/s]\n",
      "      58 | 5.92e-01 | 4.55e-02: 100%|██████████| 20/20 [00:00<00:00, 275.66it/s]\n",
      "      59 | 5.92e-01 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 280.51it/s]\n",
      "      60 | 5.92e-01 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 277.30it/s]\n",
      "      61 | 5.92e-01 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 286.09it/s]\n",
      "      62 | 5.92e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 289.71it/s]\n",
      "      63 | 5.92e-01 | 5.33e-02: 100%|██████████| 20/20 [00:00<00:00, 287.26it/s]\n",
      "      64 | 5.92e-01 | 4.64e-02: 100%|██████████| 20/20 [00:00<00:00, 284.45it/s]\n",
      "      65 | 5.92e-01 | 4.45e-02: 100%|██████████| 20/20 [00:00<00:00, 286.66it/s]\n",
      "      66 | 5.91e-01 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 279.49it/s]\n",
      "      67 | 5.92e-01 | 5.39e-02: 100%|██████████| 20/20 [00:00<00:00, 281.00it/s]\n",
      "      68 | 5.91e-01 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 283.91it/s]\n",
      "      69 | 5.92e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 290.89it/s]\n",
      "      70 | 5.91e-01 | 4.39e-02: 100%|██████████| 20/20 [00:00<00:00, 295.63it/s]\n",
      "      71 | 5.91e-01 | 5.20e-02: 100%|██████████| 20/20 [00:00<00:00, 280.53it/s]\n",
      "      72 | 5.91e-01 | 5.32e-02: 100%|██████████| 20/20 [00:00<00:00, 290.14it/s]\n",
      "      73 | 5.91e-01 | 5.49e-02: 100%|██████████| 20/20 [00:00<00:00, 282.83it/s]\n",
      "      74 | 5.91e-01 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 281.48it/s]\n",
      "      75 | 5.91e-01 | 5.36e-02: 100%|██████████| 20/20 [00:00<00:00, 281.05it/s]\n",
      "      76 | 5.91e-01 | 4.59e-02: 100%|██████████| 20/20 [00:00<00:00, 272.12it/s]\n",
      "      77 | 5.91e-01 | 4.40e-02: 100%|██████████| 20/20 [00:00<00:00, 281.58it/s]\n",
      "      78 | 5.91e-01 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 287.94it/s]\n",
      "      79 | 5.91e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 283.96it/s]\n",
      "      80 | 5.91e-01 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 288.22it/s]\n",
      "      81 | 5.91e-01 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 290.10it/s]\n",
      "      82 | 5.91e-01 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 163.42it/s]\n",
      "      83 | 5.91e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 279.32it/s]\n",
      "      84 | 5.91e-01 | 5.28e-02: 100%|██████████| 20/20 [00:00<00:00, 275.05it/s]\n",
      "      85 | 5.91e-01 | 5.10e-02: 100%|██████████| 20/20 [00:00<00:00, 262.23it/s]\n",
      "      86 | 5.91e-01 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 294.10it/s]\n",
      "      87 | 5.91e-01 | 5.33e-02: 100%|██████████| 20/20 [00:00<00:00, 272.25it/s]\n",
      "      88 | 5.91e-01 | 4.66e-02: 100%|██████████| 20/20 [00:00<00:00, 265.24it/s]\n",
      "      89 | 5.91e-01 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 269.25it/s]\n",
      "      90 | 5.91e-01 | 5.57e-02: 100%|██████████| 20/20 [00:00<00:00, 269.08it/s]\n",
      "      91 | 5.91e-01 | 4.53e-02: 100%|██████████| 20/20 [00:00<00:00, 289.12it/s]\n",
      "      92 | 5.91e-01 | 5.13e-02: 100%|██████████| 20/20 [00:00<00:00, 278.33it/s]\n",
      "      93 | 5.91e-01 | 4.92e-02: 100%|██████████| 20/20 [00:00<00:00, 283.89it/s]\n",
      "      94 | 5.91e-01 | 5.67e-02: 100%|██████████| 20/20 [00:00<00:00, 282.16it/s]\n",
      "      95 | 5.91e-01 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 281.53it/s]\n",
      "      96 | 5.91e-01 | 5.41e-02: 100%|██████████| 20/20 [00:00<00:00, 282.70it/s]\n",
      "      97 | 5.91e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 279.05it/s]\n",
      "      98 | 5.90e-01 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 268.24it/s]\n",
      "      99 | 5.90e-01 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 266.01it/s]\n"
     ]
    }
   ],
   "source": [
    "w2_, loss_logs2_, norm_logs2_ = BatchLBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    m=2,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms2 import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 10/10 [00:00<00:00, 61.67it/s]\n",
      "       1 | 1.40e+00 | 2.38e-01: 100%|██████████| 10/10 [00:00<00:00, 82.81it/s]\n",
      "       2 | 1.18e+00 | 1.71e-01: 100%|██████████| 10/10 [00:00<00:00, 66.36it/s]\n",
      "       3 | 1.09e+00 | 1.09e-01: 100%|██████████| 10/10 [00:00<00:00, 80.05it/s]\n",
      "       4 | 1.05e+00 | 8.20e-02: 100%|██████████| 10/10 [00:00<00:00, 72.56it/s]\n",
      "       5 | 1.02e+00 | 7.15e-02: 100%|██████████| 10/10 [00:00<00:00, 76.94it/s]\n",
      "       6 | 1.00e+00 | 6.54e-02: 100%|██████████| 10/10 [00:00<00:00, 74.48it/s]\n",
      "       7 | 9.84e-01 | 5.92e-02: 100%|██████████| 10/10 [00:00<00:00, 72.92it/s]\n",
      "       8 | 9.70e-01 | 5.86e-02: 100%|██████████| 10/10 [00:00<00:00, 84.65it/s]\n",
      "       9 | 9.57e-01 | 5.78e-02: 100%|██████████| 10/10 [00:00<00:00, 72.62it/s]\n",
      "      10 | 9.44e-01 | 5.74e-02: 100%|██████████| 10/10 [00:00<00:00, 72.55it/s]\n",
      "      11 | 9.33e-01 | 5.68e-02: 100%|██████████| 10/10 [00:00<00:00, 83.61it/s]\n",
      "      12 | 9.22e-01 | 5.52e-02: 100%|██████████| 10/10 [00:00<00:00, 77.49it/s]\n",
      "      13 | 9.11e-01 | 5.52e-02: 100%|██████████| 10/10 [00:00<00:00, 74.20it/s]\n",
      "      14 | 9.01e-01 | 5.68e-02: 100%|██████████| 10/10 [00:00<00:00, 73.12it/s]\n",
      "      15 | 8.91e-01 | 5.70e-02: 100%|██████████| 10/10 [00:00<00:00, 78.39it/s]\n",
      "      16 | 8.81e-01 | 5.53e-02: 100%|██████████| 10/10 [00:00<00:00, 71.24it/s]\n",
      "      17 | 8.72e-01 | 5.54e-02: 100%|██████████| 10/10 [00:00<00:00, 78.40it/s]\n",
      "      18 | 8.63e-01 | 5.43e-02: 100%|██████████| 10/10 [00:00<00:00, 54.11it/s]\n",
      "      19 | 8.55e-01 | 5.71e-02: 100%|██████████| 10/10 [00:00<00:00, 80.38it/s]\n",
      "      20 | 8.46e-01 | 5.59e-02: 100%|██████████| 10/10 [00:00<00:00, 85.29it/s]\n",
      "      21 | 8.38e-01 | 5.60e-02: 100%|██████████| 10/10 [00:00<00:00, 76.12it/s]\n",
      "      22 | 8.30e-01 | 5.72e-02: 100%|██████████| 10/10 [00:00<00:00, 79.13it/s]\n",
      "      23 | 8.21e-01 | 5.87e-02: 100%|██████████| 10/10 [00:00<00:00, 80.87it/s]\n",
      "      24 | 8.11e-01 | 6.05e-02: 100%|██████████| 10/10 [00:00<00:00, 70.23it/s]\n",
      "      25 | 7.99e-01 | 5.98e-02: 100%|██████████| 10/10 [00:00<00:00, 73.02it/s]\n",
      "      26 | 7.89e-01 | 5.54e-02: 100%|██████████| 10/10 [00:00<00:00, 72.36it/s]\n",
      "      27 | 7.81e-01 | 5.62e-02: 100%|██████████| 10/10 [00:00<00:00, 79.95it/s]\n",
      "      28 | 7.74e-01 | 5.66e-02: 100%|██████████| 10/10 [00:00<00:00, 70.47it/s]\n",
      "      29 | 7.68e-01 | 5.65e-02: 100%|██████████| 10/10 [00:00<00:00, 71.80it/s]\n",
      "      30 | 7.62e-01 | 5.48e-02: 100%|██████████| 10/10 [00:00<00:00, 80.47it/s]\n",
      "      31 | 7.57e-01 | 5.36e-02: 100%|██████████| 10/10 [00:00<00:00, 73.96it/s]\n",
      "      32 | 7.52e-01 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 67.41it/s]\n",
      "      33 | 7.47e-01 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 77.15it/s]\n",
      "      34 | 7.41e-01 | 5.50e-02: 100%|██████████| 10/10 [00:00<00:00, 82.98it/s]\n",
      "      35 | 7.31e-01 | 5.68e-02: 100%|██████████| 10/10 [00:00<00:00, 82.71it/s]\n",
      "      36 | 7.23e-01 | 5.95e-02: 100%|██████████| 10/10 [00:00<00:00, 77.66it/s]\n",
      "      37 | 7.05e-01 | 6.60e-02: 100%|██████████| 10/10 [00:00<00:00, 72.38it/s]\n",
      "      38 | 6.96e-01 | 5.59e-02: 100%|██████████| 10/10 [00:00<00:00, 76.85it/s]\n",
      "      39 | 6.91e-01 | 5.33e-02: 100%|██████████| 10/10 [00:00<00:00, 71.75it/s]\n",
      "      40 | 6.88e-01 | 5.33e-02: 100%|██████████| 10/10 [00:00<00:00, 63.33it/s]\n",
      "      41 | 6.85e-01 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 82.96it/s]\n",
      "      42 | 6.81e-01 | 4.94e-02: 100%|██████████| 10/10 [00:00<00:00, 69.03it/s]\n",
      "      43 | 6.79e-01 | 5.26e-02: 100%|██████████| 10/10 [00:00<00:00, 81.45it/s]\n",
      "      44 | 6.76e-01 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 73.40it/s]\n",
      "      45 | 6.73e-01 | 4.90e-02: 100%|██████████| 10/10 [00:00<00:00, 69.92it/s]\n",
      "      46 | 6.71e-01 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 83.08it/s]\n",
      "      47 | 6.68e-01 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 87.20it/s]\n",
      "      48 | 6.65e-01 | 5.03e-02: 100%|██████████| 10/10 [00:00<00:00, 72.32it/s]\n",
      "      49 | 6.38e-01 | 7.89e-02: 100%|██████████| 10/10 [00:00<00:00, 76.20it/s]\n",
      "      50 | 6.32e-01 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 82.52it/s]\n",
      "      51 | 6.29e-01 | 5.07e-02: 100%|██████████| 10/10 [00:00<00:00, 79.23it/s]\n",
      "      52 | 6.26e-01 | 4.33e-02: 100%|██████████| 10/10 [00:00<00:00, 54.89it/s]\n",
      "      53 | 6.24e-01 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 78.99it/s]\n",
      "      54 | 6.22e-01 | 4.68e-02: 100%|██████████| 10/10 [00:00<00:00, 79.92it/s]\n",
      "      55 | 6.19e-01 | 4.96e-02: 100%|██████████| 10/10 [00:00<00:00, 73.44it/s]\n",
      "      56 | 6.17e-01 | 4.80e-02: 100%|██████████| 10/10 [00:00<00:00, 74.06it/s]\n",
      "      57 | 6.15e-01 | 4.72e-02: 100%|██████████| 10/10 [00:00<00:00, 57.87it/s]\n",
      "      58 | 6.13e-01 | 4.62e-02: 100%|██████████| 10/10 [00:00<00:00, 92.93it/s]\n",
      "      59 | 6.11e-01 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 76.09it/s]\n",
      "      60 | 6.08e-01 | 5.90e-02: 100%|██████████| 10/10 [00:00<00:00, 82.41it/s]\n",
      "      61 | 6.02e-01 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 69.84it/s]\n",
      "      62 | 6.01e-01 | 4.80e-02: 100%|██████████| 10/10 [00:00<00:00, 76.84it/s]\n",
      "      63 | 6.00e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 74.81it/s]\n",
      "      64 | 5.99e-01 | 4.52e-02: 100%|██████████| 10/10 [00:00<00:00, 74.40it/s]\n",
      "      65 | 5.99e-01 | 4.57e-02: 100%|██████████| 10/10 [00:00<00:00, 38.89it/s]\n",
      "      66 | 5.98e-01 | 4.55e-02: 100%|██████████| 10/10 [00:00<00:00, 79.77it/s]\n",
      "      67 | 5.98e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 74.90it/s]\n",
      "      68 | 5.97e-01 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 76.73it/s]\n",
      "      69 | 5.97e-01 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 60.77it/s]\n",
      "      70 | 5.97e-01 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 76.64it/s]\n",
      "      71 | 5.97e-01 | 5.25e-02: 100%|██████████| 10/10 [00:00<00:00, 75.18it/s]\n",
      "      72 | 5.97e-01 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 73.41it/s]\n",
      "      73 | 5.97e-01 | 4.56e-02: 100%|██████████| 10/10 [00:00<00:00, 68.56it/s]\n",
      "      74 | 5.97e-01 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 73.93it/s]\n",
      "      75 | 5.97e-01 | 4.47e-02: 100%|██████████| 10/10 [00:00<00:00, 82.71it/s]\n",
      "      76 | 5.96e-01 | 4.45e-02: 100%|██████████| 10/10 [00:00<00:00, 74.72it/s]\n",
      "      77 | 5.96e-01 | 4.23e-02: 100%|██████████| 10/10 [00:00<00:00, 80.63it/s]\n",
      "      78 | 5.96e-01 | 4.78e-02: 100%|██████████| 10/10 [00:00<00:00, 72.32it/s]\n",
      "      79 | 5.96e-01 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 77.74it/s]\n",
      "      80 | 5.96e-01 | 4.71e-02: 100%|██████████| 10/10 [00:00<00:00, 65.17it/s]\n",
      "      81 | 5.96e-01 | 4.71e-02: 100%|██████████| 10/10 [00:00<00:00, 86.17it/s]\n",
      "      82 | 5.96e-01 | 4.26e-02: 100%|██████████| 10/10 [00:00<00:00, 74.38it/s]\n",
      "      83 | 5.96e-01 | 4.27e-02: 100%|██████████| 10/10 [00:00<00:00, 72.91it/s]\n",
      "      84 | 5.96e-01 | 4.43e-02: 100%|██████████| 10/10 [00:00<00:00, 38.78it/s]\n",
      "      85 | 5.96e-01 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 76.58it/s]\n",
      "      86 | 5.96e-01 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 78.30it/s]\n",
      "      87 | 5.96e-01 | 4.46e-02: 100%|██████████| 10/10 [00:00<00:00, 71.25it/s]\n",
      "      88 | 5.96e-01 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 66.09it/s]\n",
      "      89 | 5.96e-01 | 4.99e-02: 100%|██████████| 10/10 [00:00<00:00, 77.11it/s]\n",
      "      90 | 5.96e-01 | 5.03e-02: 100%|██████████| 10/10 [00:00<00:00, 85.23it/s]\n",
      "      91 | 5.95e-01 | 4.49e-02: 100%|██████████| 10/10 [00:00<00:00, 86.51it/s]\n",
      "      92 | 5.95e-01 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 83.42it/s]\n",
      "      93 | 5.95e-01 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 86.41it/s]\n",
      "      94 | 5.95e-01 | 4.57e-02: 100%|██████████| 10/10 [00:00<00:00, 78.19it/s]\n",
      "      95 | 5.95e-01 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 76.18it/s]\n",
      "      96 | 5.95e-01 | 4.36e-02: 100%|██████████| 10/10 [00:00<00:00, 75.22it/s]\n",
      "      97 | 5.95e-01 | 4.45e-02: 100%|██████████| 10/10 [00:00<00:00, 74.95it/s]\n",
      "      98 | 5.95e-01 | 4.53e-02: 100%|██████████| 10/10 [00:00<00:00, 76.89it/s]\n",
      "      99 | 5.95e-01 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 77.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# <1 min\n",
    "w3, loss_logs3, norm_logs3 = SGD(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    seed=1,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.5,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 1.78e+00 | 2.99e-01: 100%|██████████| 20/20 [00:00<00:00, 317.78it/s]\n",
      "       1 | 1.18e+00 | 1.66e-01: 100%|██████████| 20/20 [00:00<00:00, 381.69it/s]\n",
      "       2 | 1.05e+00 | 7.94e-02: 100%|██████████| 20/20 [00:00<00:00, 383.57it/s]\n",
      "       3 | 1.00e+00 | 6.43e-02: 100%|██████████| 20/20 [00:00<00:00, 381.38it/s]\n",
      "       4 | 9.71e-01 | 5.77e-02: 100%|██████████| 20/20 [00:00<00:00, 373.74it/s]\n",
      "       5 | 9.45e-01 | 5.70e-02: 100%|██████████| 20/20 [00:00<00:00, 364.23it/s]\n",
      "       6 | 9.22e-01 | 5.73e-02: 100%|██████████| 20/20 [00:00<00:00, 368.77it/s]\n",
      "       7 | 9.01e-01 | 5.62e-02: 100%|██████████| 20/20 [00:00<00:00, 377.89it/s]\n",
      "       8 | 8.81e-01 | 5.58e-02: 100%|██████████| 20/20 [00:00<00:00, 374.43it/s]\n",
      "       9 | 8.62e-01 | 5.73e-02: 100%|██████████| 20/20 [00:00<00:00, 375.57it/s]\n",
      "      10 | 8.41e-01 | 6.04e-02: 100%|██████████| 20/20 [00:00<00:00, 373.05it/s]\n",
      "      11 | 8.20e-01 | 6.20e-02: 100%|██████████| 20/20 [00:00<00:00, 376.97it/s]\n",
      "      12 | 8.01e-01 | 5.62e-02: 100%|██████████| 20/20 [00:00<00:00, 385.02it/s]\n",
      "      13 | 7.85e-01 | 5.54e-02: 100%|██████████| 20/20 [00:00<00:00, 379.10it/s]\n",
      "      14 | 7.73e-01 | 5.45e-02: 100%|██████████| 20/20 [00:00<00:00, 378.27it/s]\n",
      "      15 | 7.61e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 359.70it/s]\n",
      "      16 | 7.51e-01 | 5.23e-02: 100%|██████████| 20/20 [00:00<00:00, 373.09it/s]\n",
      "      17 | 7.41e-01 | 5.76e-02: 100%|██████████| 20/20 [00:00<00:00, 374.64it/s]\n",
      "      18 | 7.21e-01 | 6.72e-02: 100%|██████████| 20/20 [00:00<00:00, 375.46it/s]\n",
      "      19 | 6.96e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 371.36it/s]\n",
      "      20 | 6.88e-01 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 374.11it/s]\n",
      "      21 | 6.82e-01 | 5.25e-02: 100%|██████████| 20/20 [00:00<00:00, 369.12it/s]\n",
      "      22 | 6.76e-01 | 5.14e-02: 100%|██████████| 20/20 [00:00<00:00, 363.46it/s]\n",
      "      23 | 6.71e-01 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 371.61it/s]\n",
      "      24 | 6.66e-01 | 4.81e-02: 100%|██████████| 20/20 [00:00<00:00, 380.72it/s]\n",
      "      25 | 6.33e-01 | 5.02e-02: 100%|██████████| 20/20 [00:00<00:00, 363.53it/s]\n",
      "      26 | 6.27e-01 | 4.52e-02: 100%|██████████| 20/20 [00:00<00:00, 371.72it/s]\n",
      "      27 | 6.22e-01 | 4.29e-02: 100%|██████████| 20/20 [00:00<00:00, 371.75it/s]\n",
      "      28 | 6.18e-01 | 4.52e-02: 100%|██████████| 20/20 [00:00<00:00, 381.02it/s]\n",
      "      29 | 6.14e-01 | 4.59e-02: 100%|██████████| 20/20 [00:00<00:00, 377.92it/s]\n",
      "      30 | 6.08e-01 | 5.75e-02: 100%|██████████| 20/20 [00:00<00:00, 372.48it/s]\n",
      "      31 | 6.01e-01 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 370.94it/s]\n",
      "      32 | 5.99e-01 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 375.26it/s]\n",
      "      33 | 5.98e-01 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 380.57it/s]\n",
      "      34 | 5.98e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 377.15it/s]\n",
      "      35 | 5.97e-01 | 4.59e-02: 100%|██████████| 20/20 [00:00<00:00, 373.92it/s]\n",
      "      36 | 5.97e-01 | 4.55e-02: 100%|██████████| 20/20 [00:00<00:00, 372.92it/s]\n",
      "      37 | 5.97e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 368.10it/s]\n",
      "      38 | 5.96e-01 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 371.35it/s]\n",
      "      39 | 5.96e-01 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 375.47it/s]\n",
      "      40 | 5.96e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 379.35it/s]\n",
      "      41 | 5.96e-01 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 379.07it/s]\n",
      "      42 | 5.96e-01 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 328.89it/s]\n",
      "      43 | 5.96e-01 | 4.65e-02: 100%|██████████| 20/20 [00:00<00:00, 381.91it/s]\n",
      "      44 | 5.96e-01 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 376.28it/s]\n",
      "      45 | 5.95e-01 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 371.52it/s]\n",
      "      46 | 5.95e-01 | 4.66e-02: 100%|██████████| 20/20 [00:00<00:00, 363.26it/s]\n",
      "      47 | 5.95e-01 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 375.27it/s]\n",
      "      48 | 5.95e-01 | 4.75e-02: 100%|██████████| 20/20 [00:00<00:00, 370.85it/s]\n",
      "      49 | 5.95e-01 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 352.50it/s]\n",
      "      50 | 5.95e-01 | 4.59e-02: 100%|██████████| 20/20 [00:00<00:00, 359.87it/s]\n",
      "      51 | 5.95e-01 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 362.42it/s]\n",
      "      52 | 5.95e-01 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 384.22it/s]\n",
      "      53 | 5.95e-01 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 382.55it/s]\n",
      "      54 | 5.94e-01 | 4.71e-02: 100%|██████████| 20/20 [00:00<00:00, 374.94it/s]\n",
      "      55 | 5.94e-01 | 4.46e-02: 100%|██████████| 20/20 [00:00<00:00, 384.62it/s]\n",
      "      56 | 5.94e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 381.26it/s]\n",
      "      57 | 5.94e-01 | 5.29e-02: 100%|██████████| 20/20 [00:00<00:00, 373.77it/s]\n",
      "      58 | 5.94e-01 | 4.50e-02: 100%|██████████| 20/20 [00:00<00:00, 372.22it/s]\n",
      "      59 | 5.94e-01 | 4.43e-02: 100%|██████████| 20/20 [00:00<00:00, 296.58it/s]\n",
      "      60 | 5.94e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 369.00it/s]\n",
      "      61 | 5.94e-01 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 361.03it/s]\n",
      "      62 | 5.94e-01 | 5.11e-02: 100%|██████████| 20/20 [00:00<00:00, 373.41it/s]\n",
      "      63 | 5.94e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 366.33it/s]\n",
      "      64 | 5.94e-01 | 4.49e-02: 100%|██████████| 20/20 [00:00<00:00, 358.58it/s]\n",
      "      65 | 5.94e-01 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 370.55it/s]\n",
      "      66 | 5.93e-01 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 366.32it/s]\n",
      "      67 | 5.93e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 371.90it/s]\n",
      "      68 | 5.93e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 373.18it/s]\n",
      "      69 | 5.93e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 360.32it/s]\n",
      "      70 | 5.93e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 383.16it/s]\n",
      "      71 | 5.93e-01 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 357.71it/s]\n",
      "      72 | 5.93e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 365.00it/s]\n",
      "      73 | 5.93e-01 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 376.27it/s]\n",
      "      74 | 5.93e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 381.16it/s]\n",
      "      75 | 5.93e-01 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 380.07it/s]\n",
      "      76 | 5.93e-01 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 378.68it/s]\n",
      "      77 | 5.93e-01 | 5.02e-02: 100%|██████████| 20/20 [00:00<00:00, 386.37it/s]\n",
      "      78 | 5.93e-01 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 384.60it/s]\n",
      "      79 | 5.92e-01 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 383.48it/s]\n",
      "      80 | 5.92e-01 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 388.60it/s]\n",
      "      81 | 5.92e-01 | 4.55e-02: 100%|██████████| 20/20 [00:00<00:00, 375.75it/s]\n",
      "      82 | 5.92e-01 | 4.56e-02: 100%|██████████| 20/20 [00:00<00:00, 370.61it/s]\n",
      "      83 | 5.92e-01 | 4.51e-02: 100%|██████████| 20/20 [00:00<00:00, 366.21it/s]\n",
      "      84 | 5.92e-01 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 369.72it/s]\n",
      "      85 | 5.92e-01 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 368.88it/s]\n",
      "      86 | 5.92e-01 | 4.62e-02: 100%|██████████| 20/20 [00:00<00:00, 382.87it/s]\n",
      "      87 | 5.92e-01 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 380.28it/s]\n",
      "      88 | 5.92e-01 | 4.44e-02: 100%|██████████| 20/20 [00:00<00:00, 352.48it/s]\n",
      "      89 | 5.92e-01 | 5.49e-02: 100%|██████████| 20/20 [00:00<00:00, 372.52it/s]\n",
      "      90 | 5.92e-01 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 369.95it/s]\n",
      "      91 | 5.92e-01 | 4.41e-02: 100%|██████████| 20/20 [00:00<00:00, 366.81it/s]\n",
      "      92 | 5.92e-01 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 384.46it/s]\n",
      "      93 | 5.91e-01 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 370.40it/s]\n",
      "      94 | 5.92e-01 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 369.51it/s]\n",
      "      95 | 5.91e-01 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 362.88it/s]\n",
      "      96 | 5.92e-01 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 351.72it/s]\n",
      "      97 | 5.91e-01 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 372.34it/s]\n",
      "      98 | 5.91e-01 | 4.92e-02: 100%|██████████| 20/20 [00:00<00:00, 367.32it/s]\n",
      "      99 | 5.91e-01 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 371.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# <1 min\n",
    "w3_, loss_logs3_, norm_logs3_ = SGD(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    seed=1,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.5,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_logs, label=\"Batch Newton - S=100%\")\n",
    "plt.plot(loss_logs1, label=\"Batch BFGS - S=10%\")\n",
    "plt.plot(loss_logs1_, label=\"Batch BFGS - S=5%\")\n",
    "plt.plot(loss_logs2, label=\"Batch L-BFGS - S=10% - m=2\")\n",
    "plt.plot(loss_logs2_, label=\"Batch L-BFGS - S=5% - m=2\")\n",
    "plt.plot(loss_logs3, label=\"SGD - S=10%\")\n",
    "plt.plot(loss_logs3_, label=\"SGD - S=5%\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** :\n",
    "- The basic Newton method is too unstable, it is sensitive to the starting point and isn't practical due to the Hessian matrix not being invertible (not even considering the computational cost of evaluating a Hessian matrix when d is high)\n",
    "- BFGS and L-BFGS are powerful variants of the basic Newton method, they're more stable.<br> L-BFGS in particular has the advantage of not having to store the approximated inverse Hessian matrix in memory which could be particularly useful if d is high, because that would be a d² square (possibly dense) matrix. For an image of 100*100 resolution, that would be a 1e8 float matrix...\n",
    "- SGD is decent, but it converges slower in terms of iterations than the Quasi-Newton methods. One would argue that it doesn't approximate the Hessian matrix inverse, so the iterations are cheaper. <br>\n",
    "  But in this particular case, the Quasi-Newton methods are the clear winner.\n",
    "  \n",
    "- For every stochastic version of the method, there is a sweet spot between selecting the batch size, too big may be too slow but more stable, too low may be faster at the beginning but too unstable. <br> \n",
    "  Our previous experiments showed that having a medium batch size (e.g. 128-512, depending on a lot of things of course) is a good compromise between stability and convergence speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22784"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra credit (optional): \n",
    "Choose a dataset with a testing set and compare the testing loss versus the training loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
