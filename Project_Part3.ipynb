{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Binary Classification on real-world data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import norm\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation 3.1\n",
    "\n",
    "Select a dataset from the libsvm repository. The dataset should have at least 20 features\n",
    "and 1,000 training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mushrooms', <http.client.HTTPMessage at 0x2bc81ba9400>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from urllib.request import urlretrieve\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/mushrooms\", \"mushrooms\")\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a\", \"a9a\")\n",
    "# urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/a9a.t\",\"a9a.t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the dataset**\n",
    "\n",
    "It has :\n",
    "- 32 561 samples (train) / 16 281 samples (test)\n",
    "- 123 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"mushrooms\"\n",
    "X, y = load_svmlight_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8124, 112)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X.toarray(), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of the first 10 features : [0.00049237 0.05563762 0.38798621 0.10192024 0.00393895 0.45002462\n",
      " 0.39931068 0.31462334 0.00049237 0.28557361]\n"
     ]
    }
   ],
   "source": [
    "print(\"The frequency of the first 10 features :\", X_train.mean(axis=0)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The features seem very sparse, a lot are often empty**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting label 2 to -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_train -= 1\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if X's feature are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1875, 0.3903123748998999)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X train has a constant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train[:,77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(X_train, 77, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train[:,77])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a scaler class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Computing the mean and std along the features\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X-self.mean)/self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.727685308529284e-19, 1.000000000000008)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train.mean(), scaled_X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8124 111\n"
     ]
    }
   ],
   "source": [
    "N, d = X_train.shape\n",
    "print(N, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation 3.2\n",
    "\n",
    "Given your dataset, implement the associated codes for $g_S$ , $\\nabla g_S$ and $\\nabla^2 g_S$ , where S\n",
    "is a set of random indices in {1, . . . , n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        X, \n",
    "        y, \n",
    "        lbda=None,\n",
    "        regul=None,\n",
    "        batch_size=None,\n",
    "        grad_batch_size=None, \n",
    "        grad2_batch_size=None\n",
    "    ) -> None:\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.N, self.d = self.X.shape\n",
    "        # we add a regularization term if needed\n",
    "        self.lbda = lbda\n",
    "        self.regul = regul\n",
    "        # Initialize a default batch size\n",
    "        self.batch_size = batch_size\n",
    "        self.grad_batch_size = grad_batch_size\n",
    "        self.grad2_batch_size = grad2_batch_size\n",
    "        # tracking number of evaluations\n",
    "        self.func_evals = 0\n",
    "        self.grad_evals = 0\n",
    "    \n",
    "    def g_i(self, w, i):\n",
    "        self.func_evals += 1\n",
    "        return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
    "    \n",
    "    def __call__(self, w, indexes=None):\n",
    "        # Default batch size if indexes isn't given\n",
    "        indexes = self.batch_size if indexes is None else indexes\n",
    "        # We add the regularization term directly here and not in g_i\n",
    "        # (because it would be a redundant calculation to compute the mean of a term that doesn't depend on the batch chosen)\n",
    "        # This is ok bc we never actually call g_i directly outside of the class\n",
    "        if self.regul == 'l1':\n",
    "            regul = (self.lbda/2) * norm(w,1)\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = (self.lbda/2) * (norm(w,2)**2)\n",
    "        else :\n",
    "            regul = 0\n",
    "        return np.mean(self.g_i(w, indexes)) + regul\n",
    "    \n",
    "    def grad_i(self, w, i):\n",
    "        self.grad_evals += 1\n",
    "        exp_xiw = np.exp(self.X[i].dot(w))\n",
    "        return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
    "    \n",
    "    def grad(self, w, indexes=None):\n",
    "        indexes = self.grad_batch_size if indexes is None else indexes\n",
    "        grad = np.zeros(self.d)\n",
    "        for idx in indexes:\n",
    "            grad += self.grad_i(w, idx)\n",
    "        # regularization term\n",
    "        if self.regul == 'l1':\n",
    "            regul = (self.lbda/2) * np.sign(w)\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = self.lbda*w\n",
    "        else :\n",
    "            regul = 0\n",
    "        return grad/len(indexes) + regul\n",
    "    \n",
    "    def grad2_i(self, w, i):\n",
    "        # Returns a (d,d) shape array\n",
    "        self.grad_evals += self.d\n",
    "        exp_xiw = np.exp(self.X[i].dot(w))\n",
    "        scalar = 2 * exp_xiw * ( (exp_xiw**2 * (self.y[i]-1)) + (2 * exp_xiw - self.y[i]) ) / (1 + exp_xiw)**4\n",
    "        return scalar * self.X[i].reshape(self.d, 1) @ self.X[i].reshape(1, self.d)\n",
    "    \n",
    "    def grad2(self, w, indexes=None):\n",
    "        indexes = self.grad2_batch_size if indexes is None else indexes\n",
    "        grad2 = np.zeros(shape=(self.d, self.d))\n",
    "        for idx in indexes:\n",
    "            grad2 += self.grad2_i(w, idx)\n",
    "        # regularization term\n",
    "        if self.regul == 'l1':\n",
    "            regul = 0\n",
    "        elif self.regul == 'l2' :\n",
    "            regul = self.lbda*np.identity(self.d)\n",
    "        else :\n",
    "            regul = 0\n",
    "        return grad2/len(indexes) + regul\n",
    "    \n",
    "    def get_L():\n",
    "        pass\n",
    "\n",
    "    def get_batch_L():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    regul=\"l1\",\n",
    "    lbda=1./np.sqrt(N)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it makes sense to use l1 regularization here because the features are very sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if my gradients implementation are correct :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient error : 3.9365446139242415e-08\n",
      "Hessian error : 1.9046372139002516e-09\n"
     ]
    }
   ],
   "source": [
    "# <30 seconds\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "# computing func/grad on a random point\n",
    "some_w = np.random.rand(d)\n",
    "\n",
    "print(\"gradient error :\", check_grad(g.__call__, g.grad, some_w, np.arange(N)))\n",
    "\n",
    "print(\"Hessian error :\", check_grad(g.grad, g.grad2, some_w, np.arange(N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Comparison of the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "Compare the performance of the subsampling Newton method from Section 2.1 and that of the\n",
    "stochastic quasi-Newton method of Section 2.2 with a (batch) stochastic gradient approach. You may reuse\n",
    "the stochastic gradient implementation from the course notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms2 import SubNewton, BatchArmijoLineSearch, BatchBFGS, BatchLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 0.8885213000570045\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 8.89e-01 | 1.68e-01:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 8.89e-01 | 1.68e-01:   0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\algorithms2.py:83\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m batch_grad2 \u001b[38;5;241m=\u001b[39m loss_class\u001b[38;5;241m.\u001b[39mgrad2(w, grad2_idx)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Direction\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_grad2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m batch_grad)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Computing the batch loss (used in line search to avoid redundant recomputation)\u001b[39;00m\n\u001b[0;32m     86\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss_class(w, grad_idx)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\numpy\\linalg\\linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    559\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->D\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    560\u001b[0m extobj \u001b[38;5;241m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 561\u001b[0m ainv \u001b[38;5;241m=\u001b[39m \u001b[43m_umath_linalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(ainv\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\numpy\\linalg\\linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    grad2_batch_size=N//10,\n",
    "    max_epochs=20,\n",
    "    use_line_search=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Subsampling Newton method has a singular Hessian matrix for small batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n",
      "Singular matrix\n"
     ]
    }
   ],
   "source": [
    "for batch_size in 2**np.arange(10):\n",
    "    batch_idx = np.random.choice(N, size=batch_size)\n",
    "    try :\n",
    "        np.linalg.inv(g.grad2(w0, batch_idx))\n",
    "    except:\n",
    "        print(\"Singular matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However for batch_size = N (normal Newton), it is invertible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    np.linalg.inv(g.grad2(w0, np.arange(N)))\n",
    "except:\n",
    "    print(\"Singular matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with grad2_batch_size = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 8.89e-01 | 1.68e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       0 | 8.89e-01 | 1.68e-01: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=50,\n",
    "    verbose=True,\n",
    "    use_line_search=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a full Hessian, the algorithm is still very unstable (infs or NaNs), displaying the local property of this method on non-convex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try again with a normalized X train :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=1/np.sqrt(N),\n",
    "    regul=\"l1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 0.9954324732113168\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=50,\n",
    "    verbose=True,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.01,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much better..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could redefine the method with a safety layer when the hessian is not invertible, by replacing the hessian by the identity matrix. <br>\n",
    "But that wouldn't solve the issue of having inf and NaNs, and that would be equivalent to batch stochastic gradient descent anyway. <br>\n",
    "Let's try to use l2 regularization (it might help making the Hessian invertible):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=2./np.sqrt(N),\n",
    "    regul='l2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss : 1.6653530780573407\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "w0 = np.random.randn(d)\n",
    "print(\"Initial loss :\",g(w0, np.arange(N)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the initial loss was 1.3 without the regularization, meaning with regularization half of the loss is due to the penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 1/1 [00:03<00:00,  3.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha too low using 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  exp_xiw = np.exp(self.X[i].dot(w))\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n",
      "C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  return (-2 * exp_xiw * (exp_xiw * (self.y[i]-1) + self.y[i]) * self.X[i]) / (1 + exp_xiw)**3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m w, loss_logs, norm_logs \u001b[38;5;241m=\u001b[39m \u001b[43mSubNewton\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad2_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_line_search\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\algorithms2.py:116\u001b[0m, in \u001b[0;36mSubNewton\u001b[1;34m(initial_w, loss_class, grad_batch_size, grad2_batch_size, max_epochs, ground_truth, tolerance, verbose, seed, with_remplacement, use_line_search, step_size, alpha_batch_L, **Armijo_kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(norm(w\u001b[38;5;241m-\u001b[39mground_truth, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m :\n\u001b[1;32m--> 116\u001b[0m     norm_logs\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    117\u001b[0m loss_logs\u001b[38;5;241m.\u001b[39mappend(loss_class(w, np\u001b[38;5;241m.\u001b[39marange(N)))\n\u001b[0;32m    118\u001b[0m epoch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\scipy\\linalg\\_misc.py:146\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(a, ord, axis, keepdims, check_finite)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Differs from numpy only in non-finite handling and the use of blas.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_finite:\n\u001b[1;32m--> 146\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray_chkfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(a)\n",
      "File \u001b[1;32mc:\\Users\\huang\\Desktop\\Optimisation\\Project\\OML\\venv\\Lib\\site-packages\\numpy\\lib\\function_base.py:630\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    628\u001b[0m a \u001b[38;5;241m=\u001b[39m asarray(a, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar \u001b[38;5;129;01min\u001b[39;00m typecodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllFloat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(a)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    631\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray must not contain infs or NaNs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "w, loss_logs, norm_logs = SubNewton(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N,\n",
    "    grad2_batch_size=N,\n",
    "    max_epochs=100,\n",
    "    use_line_search=True,\n",
    "    seed=1,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm giving up on the Newton method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Loss(\n",
    "    X=scaled_X_train,\n",
    "    y=y_train,\n",
    "    lbda=1/np.sqrt(N),\n",
    "    regul=\"l1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try Quasi-Newton BFGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 10/10 [00:00<00:00, 86.99it/s]\n",
      "       1 | 4.89e-01 | 7.28e-02: 100%|██████████| 10/10 [00:00<00:00, 97.57it/s]\n",
      "       2 | 2.88e-01 | 6.90e-02: 100%|██████████| 10/10 [00:00<00:00, 107.76it/s]\n",
      "       3 | 1.32e-01 | 5.79e-02: 100%|██████████| 10/10 [00:00<00:00, 97.00it/s]\n",
      "       4 | 8.16e-02 | 5.47e-02: 100%|██████████| 10/10 [00:00<00:00, 97.87it/s]\n",
      "       5 | 5.87e-02 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 98.24it/s]\n",
      "       6 | 5.18e-02 | 5.18e-02: 100%|██████████| 10/10 [00:00<00:00, 85.72it/s]\n",
      "       7 | 4.83e-02 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 95.52it/s]\n",
      "       8 | 4.43e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 108.88it/s]\n",
      "       9 | 4.20e-02 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 96.71it/s]\n",
      "      10 | 3.98e-02 | 4.94e-02: 100%|██████████| 10/10 [00:00<00:00, 99.78it/s]\n",
      "      11 | 3.92e-02 | 4.71e-02: 100%|██████████| 10/10 [00:00<00:00, 100.67it/s]\n",
      "      12 | 3.92e-02 | 4.99e-02: 100%|██████████| 10/10 [00:00<00:00, 100.74it/s]\n",
      "      13 | 3.89e-02 | 4.54e-02: 100%|██████████| 10/10 [00:00<00:00, 106.42it/s]\n",
      "      14 | 3.87e-02 | 4.45e-02: 100%|██████████| 10/10 [00:00<00:00, 103.19it/s]\n",
      "      15 | 3.86e-02 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 93.01it/s]\n",
      "      16 | 3.84e-02 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 113.02it/s]\n",
      "      17 | 3.83e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 96.77it/s]\n",
      "      18 | 3.81e-02 | 4.65e-02: 100%|██████████| 10/10 [00:00<00:00, 97.67it/s]\n",
      "      19 | 3.79e-02 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 99.36it/s]\n",
      "      20 | 3.78e-02 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 103.51it/s]\n",
      "      21 | 3.76e-02 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 96.69it/s]\n",
      "      22 | 3.75e-02 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 115.33it/s]\n",
      "      23 | 3.74e-02 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 113.57it/s]\n",
      "      24 | 3.72e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 102.72it/s]\n",
      "      25 | 3.71e-02 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 93.93it/s]\n",
      "      26 | 3.69e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 93.69it/s]\n",
      "      27 | 3.69e-02 | 4.77e-02: 100%|██████████| 10/10 [00:00<00:00, 100.09it/s]\n",
      "      28 | 3.69e-02 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 92.77it/s]\n",
      "      29 | 3.69e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 106.41it/s]\n",
      "      30 | 3.69e-02 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 104.87it/s]\n",
      "      31 | 3.69e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 102.47it/s]\n",
      "      32 | 3.69e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 98.94it/s]\n",
      "      33 | 3.69e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 95.25it/s]\n",
      "      34 | 3.68e-02 | 5.03e-02: 100%|██████████| 10/10 [00:00<00:00, 95.34it/s]\n",
      "      35 | 3.68e-02 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 103.78it/s]\n",
      "      36 | 3.68e-02 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 107.50it/s]\n",
      "      37 | 3.68e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 93.33it/s]\n",
      "      38 | 3.68e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 108.77it/s]\n",
      "      39 | 3.68e-02 | 4.97e-02: 100%|██████████| 10/10 [00:00<00:00, 101.92it/s]\n",
      "      40 | 3.68e-02 | 5.03e-02: 100%|██████████| 10/10 [00:00<00:00, 101.78it/s]\n",
      "      41 | 3.68e-02 | 5.11e-02: 100%|██████████| 10/10 [00:00<00:00, 104.43it/s]\n",
      "      42 | 3.68e-02 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 93.88it/s]\n",
      "      43 | 3.68e-02 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 105.44it/s]\n",
      "      44 | 3.68e-02 | 4.97e-02: 100%|██████████| 10/10 [00:00<00:00, 107.85it/s]\n",
      "      45 | 3.68e-02 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 84.55it/s]\n",
      "      46 | 3.68e-02 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 95.16it/s]\n",
      "      47 | 3.68e-02 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 104.42it/s]\n",
      "      48 | 3.68e-02 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 108.83it/s]\n",
      "      49 | 3.68e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 107.84it/s]\n",
      "      50 | 3.68e-02 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 111.25it/s]\n",
      "      51 | 3.68e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 113.19it/s]\n",
      "      52 | 3.68e-02 | 5.27e-02: 100%|██████████| 10/10 [00:00<00:00, 91.74it/s]\n",
      "      53 | 3.68e-02 | 5.14e-02: 100%|██████████| 10/10 [00:00<00:00, 111.04it/s]\n",
      "      54 | 3.68e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 104.87it/s]\n",
      "      55 | 3.68e-02 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 115.85it/s]\n",
      "      56 | 3.68e-02 | 4.80e-02: 100%|██████████| 10/10 [00:00<00:00, 129.13it/s]\n",
      "      57 | 3.68e-02 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 123.53it/s]\n",
      "      58 | 3.68e-02 | 4.68e-02: 100%|██████████| 10/10 [00:00<00:00, 136.59it/s]\n",
      "      59 | 3.68e-02 | 4.43e-02: 100%|██████████| 10/10 [00:00<00:00, 140.97it/s]\n",
      "      60 | 3.68e-02 | 4.86e-02: 100%|██████████| 10/10 [00:00<00:00, 146.00it/s]\n",
      "      61 | 3.68e-02 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 147.48it/s]\n",
      "      62 | 3.68e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 133.04it/s]\n",
      "      63 | 3.68e-02 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 133.08it/s]\n",
      "      64 | 3.68e-02 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 149.99it/s]\n",
      "      65 | 3.68e-02 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 123.67it/s]\n",
      "      66 | 3.68e-02 | 4.46e-02: 100%|██████████| 10/10 [00:00<00:00, 149.01it/s]\n",
      "      67 | 3.68e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 148.28it/s]\n",
      "      68 | 3.68e-02 | 4.96e-02: 100%|██████████| 10/10 [00:00<00:00, 145.53it/s]\n",
      "      69 | 3.68e-02 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 137.30it/s]\n",
      "      70 | 3.68e-02 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 126.38it/s]\n",
      "      71 | 3.68e-02 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 124.75it/s]\n",
      "      72 | 3.68e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 145.90it/s]\n",
      "      73 | 3.68e-02 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 131.67it/s]\n",
      "      74 | 3.68e-02 | 5.08e-02: 100%|██████████| 10/10 [00:00<00:00, 127.21it/s]\n",
      "      75 | 3.68e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 131.65it/s]\n",
      "      76 | 3.68e-02 | 4.90e-02: 100%|██████████| 10/10 [00:00<00:00, 152.20it/s]\n",
      "      77 | 3.68e-02 | 4.90e-02: 100%|██████████| 10/10 [00:00<00:00, 156.65it/s]\n",
      "      78 | 3.68e-02 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 146.90it/s]\n",
      "      79 | 3.68e-02 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 145.22it/s]\n",
      "      80 | 3.68e-02 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 140.50it/s]\n",
      "      81 | 3.68e-02 | 4.72e-02: 100%|██████████| 10/10 [00:00<00:00, 140.11it/s]\n",
      "      82 | 3.68e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 131.78it/s]\n",
      "      83 | 3.68e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 132.06it/s]\n",
      "      84 | 3.68e-02 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 152.06it/s]\n",
      "      85 | 3.68e-02 | 5.07e-02: 100%|██████████| 10/10 [00:00<00:00, 149.99it/s]\n",
      "      86 | 3.68e-02 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 131.37it/s]\n",
      "      87 | 3.68e-02 | 5.17e-02: 100%|██████████| 10/10 [00:00<00:00, 141.91it/s]\n",
      "      88 | 3.68e-02 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 143.91it/s]\n",
      "      89 | 3.68e-02 | 4.79e-02: 100%|██████████| 10/10 [00:00<00:00, 128.07it/s]\n",
      "      90 | 3.68e-02 | 4.62e-02: 100%|██████████| 10/10 [00:00<00:00, 138.37it/s]\n",
      "      91 | 3.68e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 140.16it/s]\n",
      "      92 | 3.68e-02 | 4.66e-02: 100%|██████████| 10/10 [00:00<00:00, 146.88it/s]\n",
      "      93 | 3.68e-02 | 5.22e-02: 100%|██████████| 10/10 [00:00<00:00, 153.76it/s]\n",
      "      94 | 3.68e-02 | 5.04e-02: 100%|██████████| 10/10 [00:00<00:00, 142.07it/s]\n",
      "      95 | 3.68e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 169.01it/s]\n",
      "      96 | 3.68e-02 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 128.87it/s]\n",
      "      97 | 3.68e-02 | 4.86e-02: 100%|██████████| 10/10 [00:00<00:00, 137.12it/s]\n",
      "      98 | 3.68e-02 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 136.59it/s]\n",
      "      99 | 3.68e-02 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 143.71it/s]\n"
     ]
    }
   ],
   "source": [
    "#<1 min\n",
    "w1, loss_logs1, norm_logs1 = BatchBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    ground_truth=None,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 20/20 [00:00<00:00, 165.41it/s]\n",
      "       1 | 3.09e-01 | 6.19e-02:   0%|          | 0/20 [00:00<?, ?it/s]C:\\Users\\huang\\AppData\\Local\\Temp\\ipykernel_63572\\1868702566.py:30: RuntimeWarning: overflow encountered in exp\n",
      "  return ( self.y[i] - (1 / (1 + np.exp(-self.X[i].dot(w)))) )**2\n",
      "       1 | 3.09e-01 | 6.19e-02: 100%|██████████| 20/20 [00:00<00:00, 132.66it/s]\n",
      "       2 | 9.28e-02 | 5.86e-02: 100%|██████████| 20/20 [00:00<00:00, 186.56it/s]\n",
      "       3 | 5.26e-02 | 5.26e-02: 100%|██████████| 20/20 [00:00<00:00, 158.21it/s]\n",
      "       4 | 4.29e-02 | 5.13e-02: 100%|██████████| 20/20 [00:00<00:00, 174.86it/s]\n",
      "       5 | 3.98e-02 | 4.64e-02: 100%|██████████| 20/20 [00:00<00:00, 157.04it/s]\n",
      "       6 | 3.93e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 158.10it/s]\n",
      "       7 | 3.89e-02 | 4.48e-02: 100%|██████████| 20/20 [00:00<00:00, 169.71it/s]\n",
      "       8 | 3.86e-02 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 152.27it/s]\n",
      "       9 | 3.83e-02 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 181.65it/s]\n",
      "      10 | 3.78e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 166.13it/s]\n",
      "      11 | 3.75e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 165.29it/s]\n",
      "      12 | 3.74e-02 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 171.50it/s]\n",
      "      13 | 3.73e-02 | 4.86e-02: 100%|██████████| 20/20 [00:00<00:00, 172.10it/s]\n",
      "      14 | 3.72e-02 | 5.20e-02: 100%|██████████| 20/20 [00:00<00:00, 165.61it/s]\n",
      "      15 | 3.71e-02 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 171.26it/s]\n",
      "      16 | 3.70e-02 | 4.58e-02: 100%|██████████| 20/20 [00:00<00:00, 167.26it/s]\n",
      "      17 | 3.70e-02 | 5.25e-02: 100%|██████████| 20/20 [00:00<00:00, 173.63it/s]\n",
      "      18 | 3.70e-02 | 4.86e-02: 100%|██████████| 20/20 [00:00<00:00, 176.39it/s]\n",
      "      19 | 3.69e-02 | 4.86e-02: 100%|██████████| 20/20 [00:00<00:00, 169.07it/s]\n",
      "      20 | 3.69e-02 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 172.37it/s]\n",
      "      21 | 3.69e-02 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 168.27it/s]\n",
      "      22 | 3.69e-02 | 4.94e-02: 100%|██████████| 20/20 [00:00<00:00, 176.09it/s]\n",
      "      23 | 3.69e-02 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 173.74it/s]\n",
      "      24 | 3.69e-02 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 181.09it/s]\n",
      "      25 | 3.69e-02 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 179.35it/s]\n",
      "      26 | 3.68e-02 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 157.32it/s]\n",
      "      27 | 3.68e-02 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 160.44it/s]\n",
      "      28 | 3.68e-02 | 5.48e-02: 100%|██████████| 20/20 [00:00<00:00, 140.34it/s]\n",
      "      29 | 3.68e-02 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 162.94it/s]\n",
      "      30 | 3.68e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 120.57it/s]\n",
      "      31 | 3.68e-02 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 162.78it/s]\n",
      "      32 | 3.68e-02 | 5.10e-02: 100%|██████████| 20/20 [00:00<00:00, 164.70it/s]\n",
      "      33 | 3.68e-02 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 160.46it/s]\n",
      "      34 | 3.68e-02 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 169.34it/s]\n",
      "      35 | 3.68e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 172.16it/s]\n",
      "      36 | 3.68e-02 | 4.81e-02: 100%|██████████| 20/20 [00:00<00:00, 169.66it/s]\n",
      "      37 | 3.68e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 179.99it/s]\n",
      "      38 | 3.68e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 176.51it/s]\n",
      "      39 | 3.68e-02 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 169.63it/s]\n",
      "      40 | 3.68e-02 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 176.87it/s]\n",
      "      41 | 3.68e-02 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 181.29it/s]\n",
      "      42 | 3.68e-02 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 155.13it/s]\n",
      "      43 | 3.68e-02 | 4.55e-02: 100%|██████████| 20/20 [00:00<00:00, 162.72it/s]\n",
      "      44 | 3.68e-02 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 169.19it/s]\n",
      "      45 | 3.68e-02 | 4.64e-02: 100%|██████████| 20/20 [00:00<00:00, 164.09it/s]\n",
      "      46 | 3.68e-02 | 4.43e-02: 100%|██████████| 20/20 [00:00<00:00, 174.32it/s]\n",
      "      47 | 3.68e-02 | 4.71e-02: 100%|██████████| 20/20 [00:00<00:00, 173.47it/s]\n",
      "      48 | 3.68e-02 | 4.51e-02: 100%|██████████| 20/20 [00:00<00:00, 159.38it/s]\n",
      "      49 | 3.68e-02 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 165.16it/s]\n",
      "      50 | 3.68e-02 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 159.47it/s]\n",
      "      51 | 3.68e-02 | 4.58e-02: 100%|██████████| 20/20 [00:00<00:00, 172.14it/s]\n",
      "      52 | 3.68e-02 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 172.21it/s]\n",
      "      53 | 3.68e-02 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 183.08it/s]\n",
      "      54 | 3.68e-02 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 184.72it/s]\n",
      "      55 | 3.68e-02 | 4.60e-02: 100%|██████████| 20/20 [00:00<00:00, 201.39it/s]\n",
      "      56 | 3.68e-02 | 4.71e-02: 100%|██████████| 20/20 [00:00<00:00, 190.33it/s]\n",
      "      57 | 3.68e-02 | 4.65e-02: 100%|██████████| 20/20 [00:00<00:00, 220.88it/s]\n",
      "      58 | 3.68e-02 | 5.14e-02: 100%|██████████| 20/20 [00:00<00:00, 249.28it/s]\n",
      "      59 | 3.68e-02 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 247.62it/s]\n",
      "      60 | 3.68e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 221.64it/s]\n",
      "      61 | 3.68e-02 | 5.11e-02: 100%|██████████| 20/20 [00:00<00:00, 245.01it/s]\n",
      "      62 | 3.68e-02 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 231.82it/s]\n",
      "      63 | 3.68e-02 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 232.95it/s]\n",
      "      64 | 3.68e-02 | 4.87e-02: 100%|██████████| 20/20 [00:00<00:00, 227.54it/s]\n",
      "      65 | 3.68e-02 | 5.14e-02: 100%|██████████| 20/20 [00:00<00:00, 245.92it/s]\n",
      "      66 | 3.68e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 251.59it/s]\n",
      "      67 | 3.68e-02 | 5.13e-02: 100%|██████████| 20/20 [00:00<00:00, 217.18it/s]\n",
      "      68 | 3.68e-02 | 5.06e-02: 100%|██████████| 20/20 [00:00<00:00, 237.16it/s]\n",
      "      69 | 3.68e-02 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 229.14it/s]\n",
      "      70 | 3.68e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 153.05it/s]\n",
      "      71 | 3.68e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 233.91it/s]\n",
      "      72 | 3.68e-02 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 235.53it/s]\n",
      "      73 | 3.68e-02 | 5.27e-02: 100%|██████████| 20/20 [00:00<00:00, 245.42it/s]\n",
      "      74 | 3.68e-02 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 230.34it/s]\n",
      "      75 | 3.68e-02 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 242.26it/s]\n",
      "      76 | 3.68e-02 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 234.93it/s]\n",
      "      77 | 3.68e-02 | 4.36e-02: 100%|██████████| 20/20 [00:00<00:00, 213.09it/s]\n",
      "      78 | 3.68e-02 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 234.48it/s]\n",
      "      79 | 3.68e-02 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 242.86it/s]\n",
      "      80 | 3.68e-02 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 248.43it/s]\n",
      "      81 | 3.68e-02 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 230.48it/s]\n",
      "      82 | 3.68e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 225.83it/s]\n",
      "      83 | 3.68e-02 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 248.30it/s]\n",
      "      84 | 3.68e-02 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 230.58it/s]\n",
      "      85 | 3.68e-02 | 5.30e-02: 100%|██████████| 20/20 [00:00<00:00, 233.32it/s]\n",
      "      86 | 3.68e-02 | 4.39e-02: 100%|██████████| 20/20 [00:00<00:00, 228.77it/s]\n",
      "      87 | 3.68e-02 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 256.09it/s]\n",
      "      88 | 3.68e-02 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 240.15it/s]\n",
      "      89 | 3.68e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 215.29it/s]\n",
      "      90 | 3.68e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 224.07it/s]\n",
      "      91 | 3.68e-02 | 4.43e-02: 100%|██████████| 20/20 [00:00<00:00, 240.70it/s]\n",
      "      92 | 3.68e-02 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 229.45it/s]\n",
      "      93 | 3.68e-02 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 256.99it/s]\n",
      "      94 | 3.68e-02 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 238.26it/s]\n",
      "      95 | 3.68e-02 | 5.14e-02: 100%|██████████| 20/20 [00:00<00:00, 214.11it/s]\n",
      "      96 | 3.68e-02 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 230.57it/s]\n",
      "      97 | 3.68e-02 | 4.53e-02: 100%|██████████| 20/20 [00:00<00:00, 245.86it/s]\n",
      "      98 | 3.68e-02 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 237.72it/s]\n",
      "      99 | 3.68e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 237.98it/s]\n"
     ]
    }
   ],
   "source": [
    "#<1 min\n",
    "w1_, loss_logs1_, norm_logs1_ = BatchBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    ground_truth=None,\n",
    "    verbose=True,\n",
    "    seed=6,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L-BFGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 10/10 [00:00<00:00, 88.59it/s]\n",
      "       1 | 4.74e-01 | 6.44e-02: 100%|██████████| 10/10 [00:00<00:00, 91.09it/s]\n",
      "       2 | 2.78e-01 | 7.22e-02: 100%|██████████| 10/10 [00:00<00:00, 83.64it/s]\n",
      "       3 | 1.69e-01 | 6.18e-02: 100%|██████████| 10/10 [00:00<00:00, 77.91it/s]\n",
      "       4 | 1.14e-01 | 5.94e-02: 100%|██████████| 10/10 [00:00<00:00, 85.94it/s]\n",
      "       5 | 6.74e-02 | 5.43e-02: 100%|██████████| 10/10 [00:00<00:00, 79.08it/s]\n",
      "       6 | 5.61e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 91.13it/s]\n",
      "       7 | 5.26e-02 | 5.13e-02: 100%|██████████| 10/10 [00:00<00:00, 77.59it/s]\n",
      "       8 | 5.06e-02 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 79.92it/s]\n",
      "       9 | 4.91e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 92.29it/s]\n",
      "      10 | 4.79e-02 | 4.70e-02: 100%|██████████| 10/10 [00:00<00:00, 84.28it/s]\n",
      "      11 | 4.72e-02 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 87.14it/s]\n",
      "      12 | 4.63e-02 | 5.40e-02: 100%|██████████| 10/10 [00:00<00:00, 95.58it/s]\n",
      "      13 | 4.53e-02 | 4.61e-02: 100%|██████████| 10/10 [00:00<00:00, 93.87it/s]\n",
      "      14 | 4.46e-02 | 5.17e-02: 100%|██████████| 10/10 [00:00<00:00, 106.82it/s]\n",
      "      15 | 4.39e-02 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 91.59it/s]\n",
      "      16 | 4.33e-02 | 5.14e-02: 100%|██████████| 10/10 [00:00<00:00, 89.90it/s]\n",
      "      17 | 4.28e-02 | 5.28e-02: 100%|██████████| 10/10 [00:00<00:00, 95.82it/s]\n",
      "      18 | 4.23e-02 | 5.23e-02: 100%|██████████| 10/10 [00:00<00:00, 81.31it/s]\n",
      "      19 | 4.17e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 92.28it/s]\n",
      "      20 | 4.13e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 83.44it/s]\n",
      "      21 | 4.10e-02 | 5.46e-02: 100%|██████████| 10/10 [00:00<00:00, 83.34it/s]\n",
      "      22 | 4.07e-02 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 91.48it/s]\n",
      "      23 | 4.03e-02 | 4.60e-02: 100%|██████████| 10/10 [00:00<00:00, 86.96it/s]\n",
      "      24 | 4.03e-02 | 5.64e-02: 100%|██████████| 10/10 [00:00<00:00, 99.35it/s]\n",
      "      25 | 4.01e-02 | 5.13e-02: 100%|██████████| 10/10 [00:00<00:00, 89.60it/s]\n",
      "      26 | 3.98e-02 | 4.44e-02: 100%|██████████| 10/10 [00:00<00:00, 84.88it/s]\n",
      "      27 | 3.97e-02 | 4.38e-02: 100%|██████████| 10/10 [00:00<00:00, 96.26it/s]\n",
      "      28 | 3.95e-02 | 4.30e-02: 100%|██████████| 10/10 [00:00<00:00, 101.07it/s]\n",
      "      29 | 3.94e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 94.66it/s]\n",
      "      30 | 3.92e-02 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 79.79it/s]\n",
      "      31 | 3.91e-02 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 98.30it/s]\n",
      "      32 | 3.90e-02 | 5.18e-02: 100%|██████████| 10/10 [00:00<00:00, 65.20it/s]\n",
      "      33 | 3.90e-02 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 104.04it/s]\n",
      "      34 | 3.88e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 93.89it/s]\n",
      "      35 | 3.89e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 90.09it/s]\n",
      "      36 | 3.88e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 92.69it/s]\n",
      "      37 | 3.86e-02 | 4.53e-02: 100%|██████████| 10/10 [00:00<00:00, 103.76it/s]\n",
      "      38 | 3.86e-02 | 4.55e-02: 100%|██████████| 10/10 [00:00<00:00, 108.82it/s]\n",
      "      39 | 3.86e-02 | 4.80e-02: 100%|██████████| 10/10 [00:00<00:00, 92.10it/s]\n",
      "      40 | 3.84e-02 | 4.53e-02: 100%|██████████| 10/10 [00:00<00:00, 93.14it/s]\n",
      "      41 | 3.84e-02 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 94.56it/s]\n",
      "      42 | 3.83e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 100.48it/s]\n",
      "      43 | 3.82e-02 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 95.62it/s]\n",
      "      44 | 3.83e-02 | 4.72e-02: 100%|██████████| 10/10 [00:00<00:00, 93.99it/s]\n",
      "      45 | 3.83e-02 | 4.65e-02: 100%|██████████| 10/10 [00:00<00:00, 99.15it/s]\n",
      "      46 | 3.82e-02 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 99.21it/s]\n",
      "      47 | 3.82e-02 | 4.61e-02: 100%|██████████| 10/10 [00:00<00:00, 100.79it/s]\n",
      "      48 | 3.82e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 91.34it/s]\n",
      "      49 | 3.80e-02 | 4.58e-02: 100%|██████████| 10/10 [00:00<00:00, 81.37it/s]\n",
      "      50 | 3.79e-02 | 4.56e-02: 100%|██████████| 10/10 [00:00<00:00, 92.19it/s]\n",
      "      51 | 3.82e-02 | 5.45e-02: 100%|██████████| 10/10 [00:00<00:00, 89.68it/s]\n",
      "      52 | 3.80e-02 | 5.61e-02: 100%|██████████| 10/10 [00:00<00:00, 95.24it/s]\n",
      "      53 | 3.79e-02 | 4.50e-02: 100%|██████████| 10/10 [00:00<00:00, 94.11it/s]\n",
      "      54 | 3.79e-02 | 4.44e-02: 100%|██████████| 10/10 [00:00<00:00, 103.10it/s]\n",
      "      55 | 3.78e-02 | 4.69e-02: 100%|██████████| 10/10 [00:00<00:00, 108.51it/s]\n",
      "      56 | 3.79e-02 | 5.32e-02: 100%|██████████| 10/10 [00:00<00:00, 114.87it/s]\n",
      "      57 | 3.78e-02 | 5.90e-02: 100%|██████████| 10/10 [00:00<00:00, 111.80it/s]\n",
      "      58 | 3.78e-02 | 4.90e-02: 100%|██████████| 10/10 [00:00<00:00, 109.52it/s]\n",
      "      59 | 3.78e-02 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 124.12it/s]\n",
      "      60 | 3.78e-02 | 4.98e-02: 100%|██████████| 10/10 [00:00<00:00, 134.69it/s]\n",
      "      61 | 3.77e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 133.50it/s]\n",
      "      62 | 3.77e-02 | 5.54e-02: 100%|██████████| 10/10 [00:00<00:00, 127.88it/s]\n",
      "      63 | 3.78e-02 | 5.20e-02: 100%|██████████| 10/10 [00:00<00:00, 142.23it/s]\n",
      "      64 | 3.77e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 129.74it/s]\n",
      "      65 | 3.77e-02 | 4.77e-02: 100%|██████████| 10/10 [00:00<00:00, 117.01it/s]\n",
      "      66 | 3.78e-02 | 5.53e-02: 100%|██████████| 10/10 [00:00<00:00, 128.90it/s]\n",
      "      67 | 3.77e-02 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 136.52it/s]\n",
      "      68 | 3.76e-02 | 5.08e-02: 100%|██████████| 10/10 [00:00<00:00, 125.24it/s]\n",
      "      69 | 3.77e-02 | 4.53e-02: 100%|██████████| 10/10 [00:00<00:00, 127.82it/s]\n",
      "      70 | 3.77e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 131.25it/s]\n",
      "      71 | 3.77e-02 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 144.10it/s]\n",
      "      72 | 3.75e-02 | 5.25e-02: 100%|██████████| 10/10 [00:00<00:00, 105.40it/s]\n",
      "      73 | 3.76e-02 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 137.01it/s]\n",
      "      74 | 3.75e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 125.28it/s]\n",
      "      75 | 3.76e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 134.71it/s]\n",
      "      76 | 3.75e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 132.03it/s]\n",
      "      77 | 3.75e-02 | 4.48e-02: 100%|██████████| 10/10 [00:00<00:00, 142.07it/s]\n",
      "      78 | 3.75e-02 | 4.47e-02: 100%|██████████| 10/10 [00:00<00:00, 112.17it/s]\n",
      "      79 | 3.75e-02 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 139.27it/s]\n",
      "      80 | 3.77e-02 | 5.46e-02: 100%|██████████| 10/10 [00:00<00:00, 72.84it/s]\n",
      "      81 | 3.75e-02 | 5.25e-02: 100%|██████████| 10/10 [00:00<00:00, 131.81it/s]\n",
      "      82 | 3.75e-02 | 4.78e-02: 100%|██████████| 10/10 [00:00<00:00, 118.36it/s]\n",
      "      83 | 3.75e-02 | 4.94e-02: 100%|██████████| 10/10 [00:00<00:00, 121.58it/s]\n",
      "      84 | 3.75e-02 | 5.20e-02: 100%|██████████| 10/10 [00:00<00:00, 128.52it/s]\n",
      "      85 | 3.76e-02 | 5.06e-02: 100%|██████████| 10/10 [00:00<00:00, 120.46it/s]\n",
      "      86 | 3.78e-02 | 4.85e-02: 100%|██████████| 10/10 [00:00<00:00, 125.69it/s]\n",
      "      87 | 3.75e-02 | 4.40e-02: 100%|██████████| 10/10 [00:00<00:00, 126.42it/s]\n",
      "      88 | 3.74e-02 | 4.44e-02: 100%|██████████| 10/10 [00:00<00:00, 127.70it/s]\n",
      "      89 | 3.76e-02 | 4.99e-02: 100%|██████████| 10/10 [00:00<00:00, 141.90it/s]\n",
      "      90 | 3.76e-02 | 5.34e-02: 100%|██████████| 10/10 [00:00<00:00, 140.35it/s]\n",
      "      91 | 3.76e-02 | 5.03e-02: 100%|██████████| 10/10 [00:00<00:00, 131.13it/s]\n",
      "      92 | 3.74e-02 | 4.65e-02: 100%|██████████| 10/10 [00:00<00:00, 118.07it/s]\n",
      "      93 | 3.75e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 121.00it/s]\n",
      "      94 | 3.76e-02 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 142.31it/s]\n",
      "      95 | 3.76e-02 | 5.35e-02: 100%|██████████| 10/10 [00:00<00:00, 132.31it/s]\n",
      "      96 | 3.76e-02 | 5.36e-02: 100%|██████████| 10/10 [00:00<00:00, 122.81it/s]\n",
      "      97 | 3.74e-02 | 5.21e-02: 100%|██████████| 10/10 [00:00<00:00, 104.59it/s]\n",
      "      98 | 3.76e-02 | 4.58e-02: 100%|██████████| 10/10 [00:00<00:00, 142.13it/s]\n",
      "      99 | 3.75e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 123.69it/s]\n"
     ]
    }
   ],
   "source": [
    "#< 1 min\n",
    "w2, loss_logs2, norm_logs2 = BatchLBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    m=2,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 20/20 [00:00<00:00, 94.84it/s] \n",
      "       1 | 4.64e-01 | 6.38e-02: 100%|██████████| 20/20 [00:00<00:00, 160.45it/s]\n",
      "       2 | 2.49e-01 | 6.25e-02: 100%|██████████| 20/20 [00:00<00:00, 140.84it/s]\n",
      "       3 | 1.40e-01 | 6.13e-02: 100%|██████████| 20/20 [00:00<00:00, 139.43it/s]\n",
      "       4 | 7.85e-02 | 5.43e-02: 100%|██████████| 20/20 [00:00<00:00, 116.80it/s]\n",
      "       5 | 6.93e-02 | 5.47e-02: 100%|██████████| 20/20 [00:00<00:00, 130.98it/s]\n",
      "       6 | 6.25e-02 | 5.23e-02: 100%|██████████| 20/20 [00:00<00:00, 139.64it/s]\n",
      "       7 | 5.74e-02 | 5.20e-02: 100%|██████████| 20/20 [00:00<00:00, 147.81it/s]\n",
      "       8 | 5.41e-02 | 5.08e-02: 100%|██████████| 20/20 [00:00<00:00, 139.37it/s]\n",
      "       9 | 5.06e-02 | 5.29e-02: 100%|██████████| 20/20 [00:00<00:00, 162.88it/s]\n",
      "      10 | 4.85e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 141.42it/s]\n",
      "      11 | 4.66e-02 | 5.24e-02: 100%|██████████| 20/20 [00:00<00:00, 149.76it/s]\n",
      "      12 | 4.51e-02 | 5.51e-02: 100%|██████████| 20/20 [00:00<00:00, 146.71it/s]\n",
      "      13 | 4.37e-02 | 5.42e-02: 100%|██████████| 20/20 [00:00<00:00, 151.55it/s]\n",
      "      14 | 4.16e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 148.64it/s]\n",
      "      15 | 4.08e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 139.54it/s]\n",
      "      16 | 3.99e-02 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 154.36it/s]\n",
      "      17 | 3.96e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 143.12it/s]\n",
      "      18 | 3.91e-02 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 152.88it/s]\n",
      "      19 | 3.88e-02 | 5.47e-02: 100%|██████████| 20/20 [00:00<00:00, 152.96it/s]\n",
      "      20 | 3.86e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 156.63it/s]\n",
      "      21 | 3.91e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 151.94it/s]\n",
      "      22 | 3.84e-02 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 152.99it/s]\n",
      "      23 | 3.82e-02 | 4.49e-02: 100%|██████████| 20/20 [00:00<00:00, 150.20it/s]\n",
      "      24 | 3.81e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 148.79it/s]\n",
      "      25 | 3.82e-02 | 5.23e-02: 100%|██████████| 20/20 [00:00<00:00, 141.98it/s]\n",
      "      26 | 3.79e-02 | 4.97e-02: 100%|██████████| 20/20 [00:00<00:00, 150.86it/s]\n",
      "      27 | 3.79e-02 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 152.81it/s]\n",
      "      28 | 3.79e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 150.20it/s]\n",
      "      29 | 3.81e-02 | 5.13e-02: 100%|██████████| 20/20 [00:00<00:00, 144.22it/s]\n",
      "      30 | 3.78e-02 | 5.29e-02: 100%|██████████| 20/20 [00:00<00:00, 139.24it/s]\n",
      "      31 | 3.79e-02 | 5.26e-02: 100%|██████████| 20/20 [00:00<00:00, 143.87it/s]\n",
      "      32 | 3.79e-02 | 5.29e-02: 100%|██████████| 20/20 [00:00<00:00, 152.02it/s]\n",
      "      33 | 3.77e-02 | 4.87e-02: 100%|██████████| 20/20 [00:00<00:00, 147.89it/s]\n",
      "      34 | 3.79e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 154.79it/s]\n",
      "      35 | 3.78e-02 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 147.17it/s]\n",
      "      36 | 3.77e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 147.74it/s]\n",
      "      37 | 3.77e-02 | 4.78e-02: 100%|██████████| 20/20 [00:00<00:00, 150.76it/s]\n",
      "      38 | 3.76e-02 | 5.53e-02: 100%|██████████| 20/20 [00:00<00:00, 142.67it/s]\n",
      "      39 | 3.75e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 149.87it/s]\n",
      "      40 | 3.78e-02 | 5.08e-02: 100%|██████████| 20/20 [00:00<00:00, 157.09it/s]\n",
      "      41 | 3.79e-02 | 4.81e-02: 100%|██████████| 20/20 [00:00<00:00, 153.18it/s]\n",
      "      42 | 3.76e-02 | 5.51e-02: 100%|██████████| 20/20 [00:00<00:00, 143.95it/s]\n",
      "      43 | 3.78e-02 | 4.60e-02: 100%|██████████| 20/20 [00:00<00:00, 153.12it/s]\n",
      "      44 | 3.77e-02 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 152.63it/s]\n",
      "      45 | 3.75e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 150.98it/s]\n",
      "      46 | 3.76e-02 | 5.02e-02: 100%|██████████| 20/20 [00:00<00:00, 185.63it/s]\n",
      "      47 | 3.77e-02 | 4.69e-02: 100%|██████████| 20/20 [00:00<00:00, 189.12it/s]\n",
      "      48 | 3.81e-02 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 178.08it/s]\n",
      "      49 | 3.78e-02 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 209.32it/s]\n",
      "      50 | 3.75e-02 | 4.82e-02: 100%|██████████| 20/20 [00:00<00:00, 246.11it/s]\n",
      "      51 | 3.78e-02 | 5.40e-02: 100%|██████████| 20/20 [00:00<00:00, 204.08it/s]\n",
      "      52 | 3.79e-02 | 5.39e-02: 100%|██████████| 20/20 [00:00<00:00, 206.08it/s]\n",
      "      53 | 3.79e-02 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 213.01it/s]\n",
      "      54 | 3.78e-02 | 5.59e-02: 100%|██████████| 20/20 [00:00<00:00, 216.74it/s]\n",
      "      55 | 3.76e-02 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 214.35it/s]\n",
      "      56 | 3.74e-02 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 216.08it/s]\n",
      "      57 | 3.76e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 220.25it/s]\n",
      "      58 | 3.77e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 211.96it/s]\n",
      "      59 | 3.74e-02 | 4.29e-02: 100%|██████████| 20/20 [00:00<00:00, 194.09it/s]\n",
      "      60 | 3.75e-02 | 5.45e-02: 100%|██████████| 20/20 [00:00<00:00, 223.80it/s]\n",
      "      61 | 3.75e-02 | 4.81e-02: 100%|██████████| 20/20 [00:00<00:00, 220.52it/s]\n",
      "      62 | 3.78e-02 | 4.63e-02: 100%|██████████| 20/20 [00:00<00:00, 213.97it/s]\n",
      "      63 | 3.75e-02 | 4.64e-02: 100%|██████████| 20/20 [00:00<00:00, 216.98it/s]\n",
      "      64 | 3.75e-02 | 5.22e-02: 100%|██████████| 20/20 [00:00<00:00, 219.36it/s]\n",
      "      65 | 3.75e-02 | 4.65e-02: 100%|██████████| 20/20 [00:00<00:00, 210.36it/s]\n",
      "      66 | 3.75e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 152.58it/s]\n",
      "      67 | 3.78e-02 | 5.04e-02: 100%|██████████| 20/20 [00:00<00:00, 200.41it/s]\n",
      "      68 | 3.78e-02 | 5.98e-02: 100%|██████████| 20/20 [00:00<00:00, 200.57it/s]\n",
      "      69 | 3.77e-02 | 5.54e-02: 100%|██████████| 20/20 [00:00<00:00, 226.11it/s]\n",
      "      70 | 3.76e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 213.92it/s]\n",
      "      71 | 3.75e-02 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 210.64it/s]\n",
      "      72 | 3.75e-02 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 208.85it/s]\n",
      "      73 | 3.76e-02 | 5.26e-02: 100%|██████████| 20/20 [00:00<00:00, 210.98it/s]\n",
      "      74 | 3.75e-02 | 5.11e-02: 100%|██████████| 20/20 [00:00<00:00, 209.41it/s]\n",
      "      75 | 3.78e-02 | 5.44e-02: 100%|██████████| 20/20 [00:00<00:00, 200.91it/s]\n",
      "      76 | 3.76e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 210.99it/s]\n",
      "      77 | 3.75e-02 | 5.26e-02: 100%|██████████| 20/20 [00:00<00:00, 192.59it/s]\n",
      "      78 | 3.78e-02 | 5.25e-02: 100%|██████████| 20/20 [00:00<00:00, 203.97it/s]\n",
      "      79 | 3.74e-02 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 204.60it/s]\n",
      "      80 | 3.86e-02 | 5.83e-02: 100%|██████████| 20/20 [00:00<00:00, 213.56it/s]\n",
      "      81 | 3.74e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 213.88it/s]\n",
      "      82 | 3.75e-02 | 5.39e-02: 100%|██████████| 20/20 [00:00<00:00, 217.09it/s]\n",
      "      83 | 3.75e-02 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 209.24it/s]\n",
      "      84 | 3.75e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 192.37it/s]\n",
      "      85 | 3.77e-02 | 5.49e-02: 100%|██████████| 20/20 [00:00<00:00, 203.07it/s]\n",
      "      86 | 3.76e-02 | 5.50e-02: 100%|██████████| 20/20 [00:00<00:00, 192.23it/s]\n",
      "      87 | 3.78e-02 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 172.64it/s]\n",
      "      88 | 3.76e-02 | 5.11e-02: 100%|██████████| 20/20 [00:00<00:00, 189.47it/s]\n",
      "      89 | 3.74e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 209.04it/s]\n",
      "      90 | 3.77e-02 | 5.84e-02: 100%|██████████| 20/20 [00:00<00:00, 200.13it/s]\n",
      "      91 | 3.77e-02 | 5.01e-02: 100%|██████████| 20/20 [00:00<00:00, 186.84it/s]\n",
      "      92 | 3.76e-02 | 5.55e-02: 100%|██████████| 20/20 [00:00<00:00, 221.15it/s]\n",
      "      93 | 3.76e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 199.85it/s]\n",
      "      94 | 3.78e-02 | 5.37e-02: 100%|██████████| 20/20 [00:00<00:00, 184.28it/s]\n",
      "      95 | 3.75e-02 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 200.87it/s]\n",
      "      96 | 3.76e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 211.96it/s]\n",
      "      97 | 3.75e-02 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 175.73it/s]\n",
      "      98 | 3.77e-02 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 190.56it/s]\n",
      "      99 | 3.73e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 219.38it/s]\n"
     ]
    }
   ],
   "source": [
    "w2_, loss_logs2_, norm_logs2_ = BatchLBFGS(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    m=2,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    use_line_search=True,\n",
    "    theta=0.9,\n",
    "    initial_alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms2 import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 10/10 [00:00<00:00, 89.48it/s]\n",
      "       1 | 8.77e-01 | 1.54e-01: 100%|██████████| 10/10 [00:00<00:00, 110.28it/s]\n",
      "       2 | 7.63e-01 | 1.44e-01: 100%|██████████| 10/10 [00:00<00:00, 108.82it/s]\n",
      "       3 | 6.65e-01 | 1.32e-01: 100%|██████████| 10/10 [00:00<00:00, 113.08it/s]\n",
      "       4 | 5.86e-01 | 1.17e-01: 100%|██████████| 10/10 [00:00<00:00, 118.48it/s]\n",
      "       5 | 5.30e-01 | 1.00e-01: 100%|██████████| 10/10 [00:00<00:00, 101.40it/s]\n",
      "       6 | 4.86e-01 | 8.30e-02: 100%|██████████| 10/10 [00:00<00:00, 103.08it/s]\n",
      "       7 | 4.56e-01 | 7.21e-02: 100%|██████████| 10/10 [00:00<00:00, 116.60it/s]\n",
      "       8 | 4.34e-01 | 6.80e-02: 100%|██████████| 10/10 [00:00<00:00, 101.76it/s]\n",
      "       9 | 4.14e-01 | 6.37e-02: 100%|██████████| 10/10 [00:00<00:00, 112.67it/s]\n",
      "      10 | 3.97e-01 | 5.97e-02: 100%|██████████| 10/10 [00:00<00:00, 106.14it/s]\n",
      "      11 | 3.81e-01 | 5.95e-02: 100%|██████████| 10/10 [00:00<00:00, 115.98it/s]\n",
      "      12 | 3.67e-01 | 5.90e-02: 100%|██████████| 10/10 [00:00<00:00, 104.27it/s]\n",
      "      13 | 3.54e-01 | 5.73e-02: 100%|██████████| 10/10 [00:00<00:00, 118.38it/s]\n",
      "      14 | 3.42e-01 | 5.91e-02: 100%|██████████| 10/10 [00:00<00:00, 118.51it/s]\n",
      "      15 | 3.30e-01 | 5.72e-02: 100%|██████████| 10/10 [00:00<00:00, 118.06it/s]\n",
      "      16 | 3.19e-01 | 5.62e-02: 100%|██████████| 10/10 [00:00<00:00, 110.59it/s]\n",
      "      17 | 3.08e-01 | 5.58e-02: 100%|██████████| 10/10 [00:00<00:00, 112.09it/s]\n",
      "      18 | 2.97e-01 | 5.77e-02: 100%|██████████| 10/10 [00:00<00:00, 108.98it/s]\n",
      "      19 | 2.85e-01 | 5.77e-02: 100%|██████████| 10/10 [00:00<00:00, 106.78it/s]\n",
      "      20 | 2.74e-01 | 5.84e-02: 100%|██████████| 10/10 [00:00<00:00, 128.65it/s]\n",
      "      21 | 2.62e-01 | 5.99e-02: 100%|██████████| 10/10 [00:00<00:00, 138.91it/s]\n",
      "      22 | 2.49e-01 | 6.02e-02: 100%|██████████| 10/10 [00:00<00:00, 103.02it/s]\n",
      "      23 | 2.37e-01 | 5.81e-02: 100%|██████████| 10/10 [00:00<00:00, 105.76it/s]\n",
      "      24 | 2.24e-01 | 5.76e-02: 100%|██████████| 10/10 [00:00<00:00, 115.74it/s]\n",
      "      25 | 2.12e-01 | 5.65e-02: 100%|██████████| 10/10 [00:00<00:00, 121.61it/s]\n",
      "      26 | 2.01e-01 | 5.89e-02: 100%|██████████| 10/10 [00:00<00:00, 111.79it/s]\n",
      "      27 | 1.89e-01 | 5.87e-02: 100%|██████████| 10/10 [00:00<00:00, 115.53it/s]\n",
      "      28 | 1.77e-01 | 5.87e-02: 100%|██████████| 10/10 [00:00<00:00, 112.79it/s]\n",
      "      29 | 1.66e-01 | 5.97e-02: 100%|██████████| 10/10 [00:00<00:00, 126.52it/s]\n",
      "      30 | 1.55e-01 | 5.66e-02: 100%|██████████| 10/10 [00:00<00:00, 109.70it/s]\n",
      "      31 | 1.46e-01 | 5.92e-02: 100%|██████████| 10/10 [00:00<00:00, 109.25it/s]\n",
      "      32 | 1.36e-01 | 5.50e-02: 100%|██████████| 10/10 [00:00<00:00, 120.50it/s]\n",
      "      33 | 1.28e-01 | 5.40e-02: 100%|██████████| 10/10 [00:00<00:00, 120.31it/s]\n",
      "      34 | 1.21e-01 | 5.23e-02: 100%|██████████| 10/10 [00:00<00:00, 118.57it/s]\n",
      "      35 | 1.15e-01 | 5.44e-02: 100%|██████████| 10/10 [00:00<00:00, 109.80it/s]\n",
      "      36 | 1.09e-01 | 5.39e-02: 100%|██████████| 10/10 [00:00<00:00, 104.59it/s]\n",
      "      37 | 1.03e-01 | 5.43e-02: 100%|██████████| 10/10 [00:00<00:00, 71.03it/s]\n",
      "      38 | 9.83e-02 | 5.15e-02: 100%|██████████| 10/10 [00:00<00:00, 105.40it/s]\n",
      "      39 | 9.35e-02 | 5.38e-02: 100%|██████████| 10/10 [00:00<00:00, 113.20it/s]\n",
      "      40 | 8.93e-02 | 5.08e-02: 100%|██████████| 10/10 [00:00<00:00, 130.49it/s]\n",
      "      41 | 8.52e-02 | 5.16e-02: 100%|██████████| 10/10 [00:00<00:00, 108.04it/s]\n",
      "      42 | 8.15e-02 | 5.25e-02: 100%|██████████| 10/10 [00:00<00:00, 110.13it/s]\n",
      "      43 | 7.83e-02 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 110.90it/s]\n",
      "      44 | 7.56e-02 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 90.81it/s]\n",
      "      45 | 7.30e-02 | 4.94e-02: 100%|██████████| 10/10 [00:00<00:00, 105.15it/s]\n",
      "      46 | 7.06e-02 | 5.10e-02: 100%|██████████| 10/10 [00:00<00:00, 124.36it/s]\n",
      "      47 | 6.84e-02 | 4.74e-02: 100%|██████████| 10/10 [00:00<00:00, 107.11it/s]\n",
      "      48 | 6.64e-02 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 95.03it/s]\n",
      "      49 | 6.46e-02 | 4.95e-02: 100%|██████████| 10/10 [00:00<00:00, 95.57it/s]\n",
      "      50 | 6.29e-02 | 5.12e-02: 100%|██████████| 10/10 [00:00<00:00, 99.56it/s]\n",
      "      51 | 6.16e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 107.37it/s]\n",
      "      52 | 6.02e-02 | 4.77e-02: 100%|██████████| 10/10 [00:00<00:00, 132.28it/s]\n",
      "      53 | 5.91e-02 | 4.51e-02: 100%|██████████| 10/10 [00:00<00:00, 139.93it/s]\n",
      "      54 | 5.80e-02 | 4.91e-02: 100%|██████████| 10/10 [00:00<00:00, 134.05it/s]\n",
      "      55 | 5.72e-02 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 136.80it/s]\n",
      "      56 | 5.64e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 158.18it/s]\n",
      "      57 | 5.55e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 150.01it/s]\n",
      "      58 | 5.47e-02 | 4.96e-02: 100%|██████████| 10/10 [00:00<00:00, 153.83it/s]\n",
      "      59 | 5.37e-02 | 5.00e-02: 100%|██████████| 10/10 [00:00<00:00, 161.30it/s]\n",
      "      60 | 5.29e-02 | 4.92e-02: 100%|██████████| 10/10 [00:00<00:00, 143.97it/s]\n",
      "      61 | 5.22e-02 | 4.31e-02: 100%|██████████| 10/10 [00:00<00:00, 136.11it/s]\n",
      "      62 | 5.14e-02 | 4.96e-02: 100%|██████████| 10/10 [00:00<00:00, 142.90it/s]\n",
      "      63 | 5.06e-02 | 4.82e-02: 100%|██████████| 10/10 [00:00<00:00, 154.08it/s]\n",
      "      64 | 4.99e-02 | 4.63e-02: 100%|██████████| 10/10 [00:00<00:00, 148.09it/s]\n",
      "      65 | 4.92e-02 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 139.09it/s]\n",
      "      66 | 4.85e-02 | 4.46e-02: 100%|██████████| 10/10 [00:00<00:00, 144.21it/s]\n",
      "      67 | 4.80e-02 | 5.01e-02: 100%|██████████| 10/10 [00:00<00:00, 147.18it/s]\n",
      "      68 | 4.74e-02 | 4.87e-02: 100%|██████████| 10/10 [00:00<00:00, 159.06it/s]\n",
      "      69 | 4.68e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 160.69it/s]\n",
      "      70 | 4.63e-02 | 4.34e-02: 100%|██████████| 10/10 [00:00<00:00, 137.10it/s]\n",
      "      71 | 4.59e-02 | 4.56e-02: 100%|██████████| 10/10 [00:00<00:00, 162.55it/s]\n",
      "      72 | 4.55e-02 | 5.42e-02: 100%|██████████| 10/10 [00:00<00:00, 149.00it/s]\n",
      "      73 | 4.50e-02 | 4.94e-02: 100%|██████████| 10/10 [00:00<00:00, 142.76it/s]\n",
      "      74 | 4.47e-02 | 5.26e-02: 100%|██████████| 10/10 [00:00<00:00, 143.02it/s]\n",
      "      75 | 4.44e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 143.42it/s]\n",
      "      76 | 4.42e-02 | 4.44e-02: 100%|██████████| 10/10 [00:00<00:00, 133.80it/s]\n",
      "      77 | 4.39e-02 | 4.59e-02: 100%|██████████| 10/10 [00:00<00:00, 135.71it/s]\n",
      "      78 | 4.37e-02 | 4.86e-02: 100%|██████████| 10/10 [00:00<00:00, 131.97it/s]\n",
      "      79 | 4.34e-02 | 4.75e-02: 100%|██████████| 10/10 [00:00<00:00, 104.21it/s]\n",
      "      80 | 4.32e-02 | 4.64e-02: 100%|██████████| 10/10 [00:00<00:00, 169.80it/s]\n",
      "      81 | 4.30e-02 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 161.47it/s]\n",
      "      82 | 4.28e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 149.27it/s]\n",
      "      83 | 4.26e-02 | 4.81e-02: 100%|██████████| 10/10 [00:00<00:00, 150.47it/s]\n",
      "      84 | 4.23e-02 | 5.21e-02: 100%|██████████| 10/10 [00:00<00:00, 140.79it/s]\n",
      "      85 | 4.22e-02 | 4.97e-02: 100%|██████████| 10/10 [00:00<00:00, 160.38it/s]\n",
      "      86 | 4.19e-02 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 159.94it/s]\n",
      "      87 | 4.17e-02 | 4.84e-02: 100%|██████████| 10/10 [00:00<00:00, 159.31it/s]\n",
      "      88 | 4.15e-02 | 4.83e-02: 100%|██████████| 10/10 [00:00<00:00, 135.54it/s]\n",
      "      89 | 4.13e-02 | 4.89e-02: 100%|██████████| 10/10 [00:00<00:00, 151.65it/s]\n",
      "      90 | 4.12e-02 | 5.25e-02: 100%|██████████| 10/10 [00:00<00:00, 182.39it/s]\n",
      "      91 | 4.09e-02 | 4.67e-02: 100%|██████████| 10/10 [00:00<00:00, 149.38it/s]\n",
      "      92 | 4.07e-02 | 5.02e-02: 100%|██████████| 10/10 [00:00<00:00, 142.08it/s]\n",
      "      93 | 4.05e-02 | 5.05e-02: 100%|██████████| 10/10 [00:00<00:00, 156.45it/s]\n",
      "      94 | 4.03e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 153.56it/s]\n",
      "      95 | 4.01e-02 | 4.73e-02: 100%|██████████| 10/10 [00:00<00:00, 159.08it/s]\n",
      "      96 | 3.99e-02 | 4.88e-02: 100%|██████████| 10/10 [00:00<00:00, 167.26it/s]\n",
      "      97 | 3.98e-02 | 5.00e-02: 100%|██████████| 10/10 [00:00<00:00, 135.62it/s]\n",
      "      98 | 3.96e-02 | 4.93e-02: 100%|██████████| 10/10 [00:00<00:00, 159.99it/s]\n",
      "      99 | 3.94e-02 | 4.76e-02: 100%|██████████| 10/10 [00:00<00:00, 160.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# <1 min\n",
    "w3, loss_logs3, norm_logs3 = SGD(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//10,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    seed=1,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.5,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch   |   loss   |   norm  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       0 | 9.95e-01 | 1.49e-01: 100%|██████████| 20/20 [00:00<00:00, 279.85it/s]\n",
      "       1 | 7.66e-01 | 1.45e-01: 100%|██████████| 20/20 [00:00<00:00, 273.06it/s]\n",
      "       2 | 5.89e-01 | 1.18e-01: 100%|██████████| 20/20 [00:00<00:00, 276.61it/s]\n",
      "       3 | 4.89e-01 | 8.32e-02: 100%|██████████| 20/20 [00:00<00:00, 279.17it/s]\n",
      "       4 | 4.34e-01 | 6.80e-02: 100%|██████████| 20/20 [00:00<00:00, 279.14it/s]\n",
      "       5 | 3.96e-01 | 6.00e-02: 100%|██████████| 20/20 [00:00<00:00, 293.67it/s]\n",
      "       6 | 3.67e-01 | 5.74e-02: 100%|██████████| 20/20 [00:00<00:00, 287.73it/s]\n",
      "       7 | 3.42e-01 | 5.63e-02: 100%|██████████| 20/20 [00:00<00:00, 264.55it/s]\n",
      "       8 | 3.19e-01 | 5.54e-02: 100%|██████████| 20/20 [00:00<00:00, 282.62it/s]\n",
      "       9 | 2.97e-01 | 5.78e-02: 100%|██████████| 20/20 [00:00<00:00, 279.93it/s]\n",
      "      10 | 2.71e-01 | 5.91e-02: 100%|██████████| 20/20 [00:00<00:00, 269.30it/s]\n",
      "      11 | 2.47e-01 | 5.89e-02: 100%|██████████| 20/20 [00:00<00:00, 272.08it/s]\n",
      "      12 | 2.21e-01 | 5.93e-02: 100%|██████████| 20/20 [00:00<00:00, 279.30it/s]\n",
      "      13 | 1.98e-01 | 5.80e-02: 100%|██████████| 20/20 [00:00<00:00, 291.63it/s]\n",
      "      14 | 1.76e-01 | 5.83e-02: 100%|██████████| 20/20 [00:00<00:00, 239.09it/s]\n",
      "      15 | 1.55e-01 | 5.86e-02: 100%|██████████| 20/20 [00:00<00:00, 299.10it/s]\n",
      "      16 | 1.38e-01 | 5.52e-02: 100%|██████████| 20/20 [00:00<00:00, 287.37it/s]\n",
      "      17 | 1.21e-01 | 5.38e-02: 100%|██████████| 20/20 [00:00<00:00, 294.07it/s]\n",
      "      18 | 1.09e-01 | 5.44e-02: 100%|██████████| 20/20 [00:00<00:00, 307.37it/s]\n",
      "      19 | 9.80e-02 | 5.30e-02: 100%|██████████| 20/20 [00:00<00:00, 295.40it/s]\n",
      "      20 | 8.90e-02 | 5.03e-02: 100%|██████████| 20/20 [00:00<00:00, 244.51it/s]\n",
      "      21 | 8.14e-02 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 282.01it/s]\n",
      "      22 | 7.56e-02 | 5.23e-02: 100%|██████████| 20/20 [00:00<00:00, 286.16it/s]\n",
      "      23 | 7.08e-02 | 5.28e-02: 100%|██████████| 20/20 [00:00<00:00, 177.68it/s]\n",
      "      24 | 6.66e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 280.09it/s]\n",
      "      25 | 6.32e-02 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 287.38it/s]\n",
      "      26 | 6.04e-02 | 4.61e-02: 100%|██████████| 20/20 [00:00<00:00, 255.00it/s]\n",
      "      27 | 5.80e-02 | 4.54e-02: 100%|██████████| 20/20 [00:00<00:00, 275.71it/s]\n",
      "      28 | 5.62e-02 | 4.67e-02: 100%|██████████| 20/20 [00:00<00:00, 279.32it/s]\n",
      "      29 | 5.47e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 286.45it/s]\n",
      "      30 | 5.30e-02 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 285.62it/s]\n",
      "      31 | 5.14e-02 | 4.88e-02: 100%|██████████| 20/20 [00:00<00:00, 282.41it/s]\n",
      "      32 | 5.00e-02 | 5.45e-02: 100%|██████████| 20/20 [00:00<00:00, 299.40it/s]\n",
      "      33 | 4.86e-02 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 235.93it/s]\n",
      "      34 | 4.74e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 284.67it/s]\n",
      "      35 | 4.63e-02 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 295.36it/s]\n",
      "      36 | 4.54e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 289.38it/s]\n",
      "      37 | 4.47e-02 | 4.75e-02: 100%|██████████| 20/20 [00:00<00:00, 273.05it/s]\n",
      "      38 | 4.41e-02 | 4.74e-02: 100%|██████████| 20/20 [00:00<00:00, 262.99it/s]\n",
      "      39 | 4.37e-02 | 4.95e-02: 100%|██████████| 20/20 [00:00<00:00, 319.04it/s]\n",
      "      40 | 4.32e-02 | 4.85e-02: 100%|██████████| 20/20 [00:00<00:00, 291.46it/s]\n",
      "      41 | 4.29e-02 | 4.77e-02: 100%|██████████| 20/20 [00:00<00:00, 290.04it/s]\n",
      "      42 | 4.24e-02 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 282.94it/s]\n",
      "      43 | 4.21e-02 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 284.55it/s]\n",
      "      44 | 4.15e-02 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 278.66it/s]\n",
      "      45 | 4.11e-02 | 5.12e-02: 100%|██████████| 20/20 [00:00<00:00, 267.96it/s]\n",
      "      46 | 4.08e-02 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 288.71it/s]\n",
      "      47 | 4.04e-02 | 4.62e-02: 100%|██████████| 20/20 [00:00<00:00, 289.33it/s]\n",
      "      48 | 4.03e-02 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 286.19it/s]\n",
      "      49 | 3.95e-02 | 4.83e-02: 100%|██████████| 20/20 [00:00<00:00, 257.67it/s]\n",
      "      50 | 3.92e-02 | 5.08e-02: 100%|██████████| 20/20 [00:00<00:00, 277.22it/s]\n",
      "      51 | 3.90e-02 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 270.85it/s]\n",
      "      52 | 3.87e-02 | 4.58e-02: 100%|██████████| 20/20 [00:00<00:00, 277.94it/s]\n",
      "      53 | 3.87e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 321.95it/s]\n",
      "      54 | 3.86e-02 | 4.84e-02: 100%|██████████| 20/20 [00:00<00:00, 319.86it/s]\n",
      "      55 | 3.84e-02 | 4.90e-02: 100%|██████████| 20/20 [00:00<00:00, 313.72it/s]\n",
      "      56 | 3.83e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 310.47it/s]\n",
      "      57 | 3.83e-02 | 4.68e-02: 100%|██████████| 20/20 [00:00<00:00, 295.95it/s]\n",
      "      58 | 3.83e-02 | 4.70e-02: 100%|██████████| 20/20 [00:00<00:00, 287.84it/s]\n",
      "      59 | 3.82e-02 | 5.02e-02: 100%|██████████| 20/20 [00:00<00:00, 297.32it/s]\n",
      "      60 | 3.82e-02 | 4.45e-02: 100%|██████████| 20/20 [00:00<00:00, 308.40it/s]\n",
      "      61 | 3.82e-02 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 277.44it/s]\n",
      "      62 | 3.81e-02 | 4.72e-02: 100%|██████████| 20/20 [00:00<00:00, 294.02it/s]\n",
      "      63 | 3.80e-02 | 5.15e-02: 100%|██████████| 20/20 [00:00<00:00, 312.79it/s]\n",
      "      64 | 3.80e-02 | 4.56e-02: 100%|██████████| 20/20 [00:00<00:00, 310.31it/s]\n",
      "      65 | 3.79e-02 | 4.55e-02: 100%|██████████| 20/20 [00:00<00:00, 319.09it/s]\n",
      "      66 | 3.79e-02 | 4.99e-02: 100%|██████████| 20/20 [00:00<00:00, 271.78it/s]\n",
      "      67 | 3.79e-02 | 5.20e-02: 100%|██████████| 20/20 [00:00<00:00, 305.54it/s]\n",
      "      68 | 3.79e-02 | 5.24e-02: 100%|██████████| 20/20 [00:00<00:00, 302.93it/s]\n",
      "      69 | 3.78e-02 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 320.13it/s]\n",
      "      70 | 3.78e-02 | 4.94e-02: 100%|██████████| 20/20 [00:00<00:00, 297.19it/s]\n",
      "      71 | 3.78e-02 | 5.10e-02: 100%|██████████| 20/20 [00:00<00:00, 274.79it/s]\n",
      "      72 | 3.77e-02 | 4.97e-02: 100%|██████████| 20/20 [00:00<00:00, 309.56it/s]\n",
      "      73 | 3.77e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 306.44it/s]\n",
      "      74 | 3.77e-02 | 4.87e-02: 100%|██████████| 20/20 [00:00<00:00, 275.02it/s]\n",
      "      75 | 3.78e-02 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 316.91it/s]\n",
      "      76 | 3.77e-02 | 5.05e-02: 100%|██████████| 20/20 [00:00<00:00, 308.27it/s]\n",
      "      77 | 3.76e-02 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 313.95it/s]\n",
      "      78 | 3.77e-02 | 5.07e-02: 100%|██████████| 20/20 [00:00<00:00, 316.22it/s]\n",
      "      79 | 3.75e-02 | 4.73e-02: 100%|██████████| 20/20 [00:00<00:00, 309.46it/s]\n",
      "      80 | 3.77e-02 | 4.64e-02: 100%|██████████| 20/20 [00:00<00:00, 300.57it/s]\n",
      "      81 | 3.76e-02 | 5.19e-02: 100%|██████████| 20/20 [00:00<00:00, 328.86it/s]\n",
      "      82 | 3.76e-02 | 4.76e-02: 100%|██████████| 20/20 [00:00<00:00, 315.07it/s]\n",
      "      83 | 3.76e-02 | 4.79e-02: 100%|██████████| 20/20 [00:00<00:00, 306.37it/s]\n",
      "      84 | 3.75e-02 | 5.39e-02: 100%|██████████| 20/20 [00:00<00:00, 313.32it/s]\n",
      "      85 | 3.76e-02 | 5.16e-02: 100%|██████████| 20/20 [00:00<00:00, 321.25it/s]\n",
      "      86 | 3.76e-02 | 5.21e-02: 100%|██████████| 20/20 [00:00<00:00, 303.85it/s]\n",
      "      87 | 3.75e-02 | 4.89e-02: 100%|██████████| 20/20 [00:00<00:00, 321.32it/s]\n",
      "      88 | 3.76e-02 | 4.80e-02: 100%|██████████| 20/20 [00:00<00:00, 163.93it/s]\n",
      "      89 | 3.75e-02 | 5.00e-02: 100%|██████████| 20/20 [00:00<00:00, 272.21it/s]\n",
      "      90 | 3.75e-02 | 5.28e-02: 100%|██████████| 20/20 [00:00<00:00, 296.30it/s]\n",
      "      91 | 3.76e-02 | 4.93e-02: 100%|██████████| 20/20 [00:00<00:00, 296.41it/s]\n",
      "      92 | 3.75e-02 | 5.47e-02: 100%|██████████| 20/20 [00:00<00:00, 321.19it/s]\n",
      "      93 | 3.76e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 319.94it/s]\n",
      "      94 | 3.76e-02 | 4.96e-02: 100%|██████████| 20/20 [00:00<00:00, 324.01it/s]\n",
      "      95 | 3.75e-02 | 4.58e-02: 100%|██████████| 20/20 [00:00<00:00, 299.21it/s]\n",
      "      96 | 3.77e-02 | 4.98e-02: 100%|██████████| 20/20 [00:00<00:00, 319.96it/s]\n",
      "      97 | 3.76e-02 | 4.91e-02: 100%|██████████| 20/20 [00:00<00:00, 299.75it/s]\n",
      "      98 | 3.74e-02 | 5.17e-02: 100%|██████████| 20/20 [00:00<00:00, 305.01it/s]\n",
      "      99 | 3.75e-02 | 5.37e-02: 100%|██████████| 20/20 [00:00<00:00, 311.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# <1 min\n",
    "w3_, loss_logs3_, norm_logs3_ = SGD(\n",
    "    initial_w=w0,\n",
    "    loss_class=g,\n",
    "    grad_batch_size=N//20,\n",
    "    max_epochs=100,\n",
    "    tolerance=1e-3,\n",
    "    seed=1,\n",
    "    use_line_search=True,\n",
    "    initial_alpha=0.5,\n",
    "    theta=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(loss_logs, label=\"Batch Newton - S=100%\")\n",
    "plt.plot(loss_logs1, label=\"Batch BFGS - S=10%\")\n",
    "plt.plot(loss_logs1_, label=\"Batch BFGS - S=5%\")\n",
    "plt.plot(loss_logs2, label=\"Batch L-BFGS - S=10% - m=2\")\n",
    "plt.plot(loss_logs2_, label=\"Batch L-BFGS - S=5% - m=2\")\n",
    "plt.plot(loss_logs3, label=\"SGD - S=10%\")\n",
    "plt.plot(loss_logs3_, label=\"SGD - S=5%\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** :\n",
    "- The basic Newton method is too unstable, it is sensitive to the starting point and isn't practical due to the Hessian matrix not being invertible (not even considering the computational cost of evaluating a Hessian matrix when d is high)\n",
    "- BFGS and L-BFGS are powerful variants of the basic Newton method, they're more stable.<br> L-BFGS in particular has the advantage of not having to store the approximated inverse Hessian matrix in memory which could be particularly useful if d is high, because that would be a d² square (possibly dense) matrix. For an image of 100*100 resolution, that would be a 1e8 float matrix...\n",
    "- SGD is decent, but it converges slower in terms of iterations than the Quasi-Newton methods. One would argue that it doesn't approximate the Hessian matrix inverse, so the iterations are cheaper. <br>\n",
    "  But in this particular case, the Quasi-Newton methods are the clear winner.\n",
    "  \n",
    "- For every stochastic version of the method, there is a sweet spot between selecting the batch size, too big may be too slow but more stable, too low may be faster at the beginning but too unstable. <br> \n",
    "  Our previous experiments showed that having a medium batch size (e.g. 128-512, depending on a lot of things of course) is a good compromise between stability and convergence speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12550"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra credit (optional): \n",
    "Choose a dataset with a testing set and compare the testing loss versus the training loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
